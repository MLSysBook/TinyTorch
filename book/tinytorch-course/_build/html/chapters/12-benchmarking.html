

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Benchmarking &#8212; TinyğŸ”¥Torch: Build ML Systems from Scratch</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/12-benchmarking';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MLOps" href="13-mlops.html" />
    <link rel="prev" title="Kernels" href="11-kernels.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="TinyğŸ”¥Torch: Build ML Systems from Scratch - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="TinyğŸ”¥Torch: Build ML Systems from Scratch - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    TinyğŸ”¥Torch: Build Machine Learning Systems from Scratch
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Usage Paths</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../usage-paths/quick-exploration.html">ğŸ”¬ Quick Exploration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage-paths/serious-development.html">ğŸ—ï¸ Serious Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage-paths/classroom-use.html">ğŸ‘¨â€ğŸ« Classroom Use</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Foundation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="00-setup.html">0. Development Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-tensor.html">1. Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-activations.html">2. Activations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Building Blocks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="03-layers.html">3. Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-networks.html">4. Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-cnn.html">5. CNNs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Training Systems</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="06-dataloader.html">DataLoader</a></li>

<li class="toctree-l1"><a class="reference internal" href="07-autograd.html">7. Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-optimizers.html">8. Optimizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="09-training.html">9. Training</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Production &amp; Performance</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="10-compression.html">10. Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-kernels.html">11. Kernels</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">12. Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="13-mlops.html">13. MLOps</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/VJ/TinyTorch" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/VJ/TinyTorch/edit/main/book/tinytorch-course/chapters/12-benchmarking.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/VJ/TinyTorch/issues/new?title=Issue%20on%20page%20%2Fchapters/12-benchmarking.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapters/12-benchmarking.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Benchmarking</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-this-code-lives-in-the-final-package">ğŸ“¦ Where This Code Lives in the Final Package</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-ml-benchmarking">What is ML Benchmarking?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-systematic-evaluation-problem">The Systematic Evaluation Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mlperf-architecture">The MLPerf Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-four-components">The Four Components</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-this-matters">Why This Matters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-examples">Real-World Examples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-benchmark-scenarios-how-to-measure-performance">Step 1: Benchmark Scenarios - How to Measure Performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-three-standard-scenarios">The Three Standard Scenarios</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#single-stream-scenario">1. Single-Stream Scenario</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#server-scenario">2. Server Scenario</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#offline-scenario">3. Offline Scenario</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-foundation">Mathematical Foundation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-multiple-scenarios">Why Multiple Scenarios?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-statistical-validation-ensuring-meaningful-results">Step 2: Statistical Validation - Ensuring Meaningful Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-significance-problem">The Significance Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mlperf-solution">The MLPerf Solution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-statistical-concepts">Key Statistical Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-size-calculation">Sample Size Calculation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-test-benchmark-scenarios">ğŸ§ª Unit Test: Benchmark Scenarios</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-statistical-validation-ensuring-meaningful-results">Step 3: Statistical Validation - Ensuring Meaningful Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-confidence-problem">The Confidence Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-testing-for-ml">Statistical Testing for ML</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-test-statistical-validation">ğŸ§ª Unit Test: Statistical Validation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-the-tinytorchperf-framework-putting-it-all-together">Step 4: The TinyTorchPerf Framework - Putting It All Together</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-complete-mlperf-inspired-framework">The Complete MLPerf-Inspired Framework</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-test-tinytorchperf-framework">ğŸ§ª Unit Test: TinyTorchPerf Framework</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-professional-reporting-project-ready-results">Step 5: Professional Reporting - Project-Ready Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-professional-reports-matter">Why Professional Reports Matter</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-test-performance-reporter">ğŸ§ª Unit Test: Performance Reporter</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comprehensive-integration-test">Comprehensive Integration Test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-testing">ğŸ§ª Module Testing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-summary-systematic-ml-performance-evaluation">ğŸ¯ Module Summary: Systematic ML Performance Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-you-ve-built">What Youâ€™ve Built</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-insights">Key Insights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-connections">Real-World Connections</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#achievement-unlocked">ğŸ† Achievement Unlocked</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="benchmarking">
<h1>Benchmarking<a class="headerlink" href="#benchmarking" title="Permalink to this heading">#</a></h1>
<div class="tip admonition">
<p class="admonition-title">Interactive Learning</p>
<p>ğŸš€ <strong>Launch Binder</strong>: Click the rocket icon above to run this chapter interactively!</p>
<p>ğŸ’¾ <strong>Save Your Work</strong>: Download your completed notebook when done.</p>
<p>ğŸ—ï¸ <strong>Build Locally</strong>: Ready for serious development? <a class="reference external" href="https://github.com/your-org/tinytorch">Fork the repo</a> and work locally with the full <code class="docutils literal notranslate"><span class="pre">tito</span></code> workflow.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| default_exp core.benchmarking</span>

<span class="c1">#| export</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">statistics</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="c1"># Import our TinyTorch dependencies</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tinytorch.core.tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
    <span class="kn">from</span> <span class="nn">tinytorch.core.networks</span> <span class="kn">import</span> <span class="n">Sequential</span>
    <span class="kn">from</span> <span class="nn">tinytorch.core.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
    <span class="kn">from</span> <span class="nn">tinytorch.core.activations</span> <span class="kn">import</span> <span class="n">ReLU</span><span class="p">,</span> <span class="n">Softmax</span>
    <span class="kn">from</span> <span class="nn">tinytorch.core.dataloader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="c1"># For development, import from local modules</span>
    <span class="n">parent_dirs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">),</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;01_tensor&#39;</span><span class="p">),</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">),</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;03_layers&#39;</span><span class="p">),</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">),</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;02_activations&#39;</span><span class="p">),</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">),</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;04_networks&#39;</span><span class="p">),</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">),</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;06_dataloader&#39;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">parent_dirs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">path</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">tensor_dev</span> <span class="kn">import</span> <span class="n">Tensor</span>
        <span class="kn">from</span> <span class="nn">networks_dev</span> <span class="kn">import</span> <span class="n">Sequential</span>
        <span class="kn">from</span> <span class="nn">layers_dev</span> <span class="kn">import</span> <span class="n">Dense</span>
        <span class="kn">from</span> <span class="nn">activations_dev</span> <span class="kn">import</span> <span class="n">ReLU</span><span class="p">,</span> <span class="n">Softmax</span>
        <span class="kn">from</span> <span class="nn">dataloader_dev</span> <span class="kn">import</span> <span class="n">DataLoader</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="c1"># Fallback for missing modules</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âš ï¸  Some TinyTorch modules not available - using minimal implementations&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">5</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1">#| default_exp core.benchmarking</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> 
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1">#| export</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="ne">----&gt; </span><span class="mi">5</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">import</span> <span class="nn">time</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">import</span> <span class="nn">statistics</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;matplotlib&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| hide</span>
<span class="c1">#| export</span>
<span class="k">def</span> <span class="nf">_should_show_plots</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if we should show plots (disable during testing)&quot;&quot;&quot;</span>
    <span class="n">is_pytest</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s1">&#39;pytest&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span> <span class="ow">or</span>
        <span class="s1">&#39;test&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span> <span class="ow">or</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PYTEST_CURRENT_TEST&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span>
        <span class="nb">any</span><span class="p">(</span><span class="s1">&#39;test&#39;</span> <span class="ow">in</span> <span class="n">arg</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="ow">or</span>
        <span class="nb">any</span><span class="p">(</span><span class="s1">&#39;pytest&#39;</span> <span class="ow">in</span> <span class="n">arg</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="ow">not</span> <span class="n">is_pytest</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸ“Š TinyTorch Benchmarking Module&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;NumPy version: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Python version: </span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="o">.</span><span class="n">major</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="o">.</span><span class="n">minor</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ready to build professional ML benchmarking tools!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="where-this-code-lives-in-the-final-package">
<h2>ğŸ“¦ Where This Code Lives in the Final Package<a class="headerlink" href="#where-this-code-lives-in-the-final-package" title="Permalink to this heading">#</a></h2>
<p><strong>Learning Side:</strong> You work in <code class="docutils literal notranslate"><span class="pre">modules/source/12_benchmarking/benchmarking_dev.py</span></code><br />
<strong>Building Side:</strong> Code exports to <code class="docutils literal notranslate"><span class="pre">tinytorch.core.benchmarking</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Final package structure:</span>
<span class="kn">from</span> <span class="nn">tinytorch.core.benchmarking</span> <span class="kn">import</span> <span class="n">TinyTorchPerf</span><span class="p">,</span> <span class="n">BenchmarkScenarios</span>
<span class="kn">from</span> <span class="nn">tinytorch.core.benchmarking</span> <span class="kn">import</span> <span class="n">StatisticalValidator</span><span class="p">,</span> <span class="n">PerformanceReporter</span>
</pre></div>
</div>
<p><strong>Why this matters:</strong></p>
<ul class="simple">
<li><p><strong>Learning:</strong> Deep understanding of systematic evaluation</p></li>
<li><p><strong>Production:</strong> Professional benchmarking methodology</p></li>
<li><p><strong>Projects:</strong> Tools for validating your ML project performance</p></li>
<li><p><strong>Career:</strong> Industry-standard skills for ML engineering roles</p></li>
</ul>
</section>
<section id="what-is-ml-benchmarking">
<h2>What is ML Benchmarking?<a class="headerlink" href="#what-is-ml-benchmarking" title="Permalink to this heading">#</a></h2>
<section id="the-systematic-evaluation-problem">
<h3>The Systematic Evaluation Problem<a class="headerlink" href="#the-systematic-evaluation-problem" title="Permalink to this heading">#</a></h3>
<p>When you build ML systems, you need to answer critical questions:</p>
<ul class="simple">
<li><p><strong>Is my model actually better?</strong> Statistical significance vs random variation</p></li>
<li><p><strong>How does it perform in production?</strong> Latency, throughput, resource usage</p></li>
<li><p><strong>Which approach should I choose?</strong> Systematic comparison methodology</p></li>
<li><p><strong>Can I trust my results?</strong> Avoiding common benchmarking pitfalls</p></li>
</ul>
</section>
<section id="the-mlperf-architecture">
<h3>The MLPerf Architecture<a class="headerlink" href="#the-mlperf-architecture" title="Permalink to this heading">#</a></h3>
<p>MLPerf (Machine Learning Performance) defines the industry standard for ML benchmarking:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Generator â”‚â”€â”€â”€â–¶â”‚ System Under    â”‚â”€â”€â”€â–¶â”‚    Dataset      â”‚
â”‚   (Controls     â”‚    â”‚ Test (Your ML   â”‚    â”‚ (Standardized   â”‚
â”‚    Queries)     â”‚    â”‚    Model)       â”‚    â”‚  Evaluation)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre></div>
</div>
</section>
<section id="the-four-components">
<h3>The Four Components<a class="headerlink" href="#the-four-components" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>System Under Test (SUT)</strong>: Your ML model/system being evaluated</p></li>
<li><p><strong>Dataset</strong>: Standardized evaluation data (CIFAR-10, ImageNet, etc.)</p></li>
<li><p><strong>Model</strong>: The specific architecture and weights being tested</p></li>
<li><p><strong>Load Generator</strong>: Controls how evaluation queries are sent to the SUT</p></li>
</ol>
</section>
<section id="why-this-matters">
<h3>Why This Matters<a class="headerlink" href="#why-this-matters" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Reproducibility</strong>: Others can verify your results</p></li>
<li><p><strong>Comparability</strong>: Fair comparison between different approaches</p></li>
<li><p><strong>Statistical validity</strong>: Meaningful conclusions from your data</p></li>
<li><p><strong>Industry standards</strong>: Skills youâ€™ll use in ML engineering careers</p></li>
</ul>
</section>
<section id="real-world-examples">
<h3>Real-World Examples<a class="headerlink" href="#real-world-examples" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Google</strong>: Uses similar patterns for production ML system evaluation</p></li>
<li><p><strong>Meta</strong>: A/B testing frameworks follow these principles</p></li>
<li><p><strong>OpenAI</strong>: GPT model comparisons use systematic benchmarking</p></li>
<li><p><strong>Research</strong>: All major ML conferences require proper evaluation methodology</p></li>
</ul>
</section>
</section>
<section id="step-1-benchmark-scenarios-how-to-measure-performance">
<h2>Step 1: Benchmark Scenarios - How to Measure Performance<a class="headerlink" href="#step-1-benchmark-scenarios-how-to-measure-performance" title="Permalink to this heading">#</a></h2>
<section id="the-three-standard-scenarios">
<h3>The Three Standard Scenarios<a class="headerlink" href="#the-three-standard-scenarios" title="Permalink to this heading">#</a></h3>
<p>Different use cases require different performance measurements:</p>
<section id="single-stream-scenario">
<h4>1. Single-Stream Scenario<a class="headerlink" href="#single-stream-scenario" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Use case</strong>: Mobile/edge inference, interactive applications</p></li>
<li><p><strong>Pattern</strong>: Send next query only after previous completes</p></li>
<li><p><strong>Metric</strong>: 90th percentile latency (tail latency)</p></li>
<li><p><strong>Why</strong>: Users care about worst-case response time</p></li>
</ul>
</section>
<section id="server-scenario">
<h4>2. Server Scenario<a class="headerlink" href="#server-scenario" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Use case</strong>: Production web services, API endpoints</p></li>
<li><p><strong>Pattern</strong>: Poisson distribution of concurrent queries</p></li>
<li><p><strong>Metric</strong>: Queries per second (QPS) at acceptable latency</p></li>
<li><p><strong>Why</strong>: Servers handle multiple simultaneous requests</p></li>
</ul>
</section>
<section id="offline-scenario">
<h4>3. Offline Scenario<a class="headerlink" href="#offline-scenario" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Use case</strong>: Batch processing, data center workloads</p></li>
<li><p><strong>Pattern</strong>: Send all samples at once for batch processing</p></li>
<li><p><strong>Metric</strong>: Throughput (samples per second)</p></li>
<li><p><strong>Why</strong>: Batch jobs care about total processing time</p></li>
</ul>
</section>
</section>
<section id="mathematical-foundation">
<h3>Mathematical Foundation<a class="headerlink" href="#mathematical-foundation" title="Permalink to this heading">#</a></h3>
<p>Each scenario tests different aspects:</p>
<ul class="simple">
<li><p><strong>Latency</strong>: Time for single sample = f(model_complexity, hardware)</p></li>
<li><p><strong>Throughput</strong>: Samples per second = f(parallelism, batch_size)</p></li>
<li><p><strong>Efficiency</strong>: Resource utilization = f(memory, compute, bandwidth)</p></li>
</ul>
</section>
<section id="why-multiple-scenarios">
<h3>Why Multiple Scenarios?<a class="headerlink" href="#why-multiple-scenarios" title="Permalink to this heading">#</a></h3>
<p>Real ML systems have different requirements:</p>
<ul class="simple">
<li><p><strong>Chatbot</strong>: Low latency for good user experience</p></li>
<li><p><strong>Image API</strong>: High throughput for many concurrent users</p></li>
<li><p><strong>Data pipeline</strong>: Maximum batch processing efficiency</p></li>
</ul>
</section>
</section>
<section id="step-2-statistical-validation-ensuring-meaningful-results">
<h2>Step 2: Statistical Validation - Ensuring Meaningful Results<a class="headerlink" href="#step-2-statistical-validation-ensuring-meaningful-results" title="Permalink to this heading">#</a></h2>
<section id="the-significance-problem">
<h3>The Significance Problem<a class="headerlink" href="#the-significance-problem" title="Permalink to this heading">#</a></h3>
<p>Common benchmarking mistakes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># BAD: Single run, no statistical validation</span>
<span class="n">result_a</span> <span class="o">=</span> <span class="n">model_a</span><span class="o">.</span><span class="n">run_once</span><span class="p">()</span>  <span class="c1"># 94.2% accuracy</span>
<span class="n">result_b</span> <span class="o">=</span> <span class="n">model_b</span><span class="o">.</span><span class="n">run_once</span><span class="p">()</span>  <span class="c1"># 94.7% accuracy</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model B is better!&quot;</span><span class="p">)</span>  <span class="c1"># Maybe, maybe not...</span>
</pre></div>
</div>
</section>
<section id="the-mlperf-solution">
<h3>The MLPerf Solution<a class="headerlink" href="#the-mlperf-solution" title="Permalink to this heading">#</a></h3>
<p>Proper statistical validation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># GOOD: Multiple runs with confidence intervals</span>
<span class="n">results_a</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_a</span><span class="o">.</span><span class="n">run</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>  <span class="c1"># [93.8, 94.1, 94.3, ...]</span>
<span class="n">results_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_b</span><span class="o">.</span><span class="n">run</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>  <span class="c1"># [94.2, 94.5, 94.9, ...]</span>
<span class="n">significance</span> <span class="o">=</span> <span class="n">statistical_test</span><span class="p">(</span><span class="n">results_a</span><span class="p">,</span> <span class="n">results_b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model B is </span><span class="si">{</span><span class="n">significance</span><span class="o">.</span><span class="n">p_value</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">0.05</span><span class="si">}</span><span class="s2"> better with p=</span><span class="si">{</span><span class="n">significance</span><span class="o">.</span><span class="n">p_value</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="key-statistical-concepts">
<h3>Key Statistical Concepts<a class="headerlink" href="#key-statistical-concepts" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Confidence intervals</strong>: Range of likely true values</p></li>
<li><p><strong>P-values</strong>: Probability that difference is due to chance</p></li>
<li><p><strong>Effect size</strong>: Magnitude of improvement (not just significance)</p></li>
<li><p><strong>Multiple comparisons</strong>: Adjusting for testing many approaches</p></li>
</ul>
</section>
<section id="sample-size-calculation">
<h3>Sample Size Calculation<a class="headerlink" href="#sample-size-calculation" title="Permalink to this heading">#</a></h3>
<p>MLPerf uses this formula for minimum samples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="n">Î¦</span><span class="o">^</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)((</span><span class="mi">1</span><span class="o">-</span><span class="n">C</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span> <span class="o">/</span> <span class="n">MOE</span><span class="o">^</span><span class="mi">2</span>
</pre></div>
</div>
<p>Where:</p>
<ul class="simple">
<li><p>C = confidence level (0.99)</p></li>
<li><p>p = percentile (0.90 for 90th percentile)</p></li>
<li><p>MOE = margin of error ((1-p)/20)</p></li>
</ul>
<p>For 90th percentile with 99% confidence: <strong>n = 24,576 samples</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| export</span>
<span class="k">class</span> <span class="nc">BenchmarkScenario</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Standard benchmark scenarios from MLPerf&quot;&quot;&quot;</span>
    <span class="n">SINGLE_STREAM</span> <span class="o">=</span> <span class="s2">&quot;single_stream&quot;</span>
    <span class="n">SERVER</span> <span class="o">=</span> <span class="s2">&quot;server&quot;</span>
    <span class="n">OFFLINE</span> <span class="o">=</span> <span class="s2">&quot;offline&quot;</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">BenchmarkResult</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Results from a benchmark run&quot;&quot;&quot;</span>
    <span class="n">scenario</span><span class="p">:</span> <span class="n">BenchmarkScenario</span>
    <span class="n">latencies</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span>  <span class="c1"># All latency measurements in seconds</span>
    <span class="n">throughput</span><span class="p">:</span> <span class="nb">float</span>      <span class="c1"># Samples per second</span>
    <span class="n">accuracy</span><span class="p">:</span> <span class="nb">float</span>        <span class="c1"># Model accuracy (0-1)</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1">#| export</span>
<span class="k">class</span> <span class="nc">BenchmarkScenarios</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements the three standard MLPerf benchmark scenarios.</span>
<span class="sd">    </span>
<span class="sd">    TODO: Implement the three benchmark scenarios following MLPerf patterns.</span>
<span class="sd">    </span>
<span class="sd">    UNDERSTANDING THE SCENARIOS:</span>
<span class="sd">    1. Single-Stream: Send queries one at a time, measure latency</span>
<span class="sd">    2. Server: Send queries following Poisson distribution, measure QPS</span>
<span class="sd">    3. Offline: Send all queries at once, measure total throughput</span>
<span class="sd">    </span>
<span class="sd">    IMPLEMENTATION APPROACH:</span>
<span class="sd">    1. Each scenario should run the model multiple times</span>
<span class="sd">    2. Collect latency measurements for each run</span>
<span class="sd">    3. Calculate appropriate metrics for each scenario</span>
<span class="sd">    4. Return BenchmarkResult with all measurements</span>
<span class="sd">    </span>
<span class="sd">    EXAMPLE USAGE:</span>
<span class="sd">    scenarios = BenchmarkScenarios()</span>
<span class="sd">    result = scenarios.single_stream(model, dataset, num_queries=1000)</span>
<span class="sd">    print(f&quot;90th percentile latency: {result.latencies[int(0.9 * len(result.latencies))]} seconds&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">single_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span> <span class="n">num_queries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BenchmarkResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run single-stream benchmark scenario.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement single-stream benchmarking.</span>
<span class="sd">        </span>
<span class="sd">        STEP-BY-STEP:</span>
<span class="sd">        1. Initialize empty list for latencies</span>
<span class="sd">        2. For each query (up to num_queries):</span>
<span class="sd">           a. Get next sample from dataset (cycle if needed)</span>
<span class="sd">           b. Record start time</span>
<span class="sd">           c. Run model on sample</span>
<span class="sd">           d. Record end time</span>
<span class="sd">           e. Calculate latency = end - start</span>
<span class="sd">           f. Add latency to list</span>
<span class="sd">        3. Calculate throughput = num_queries / total_time</span>
<span class="sd">        4. Calculate accuracy if possible</span>
<span class="sd">        5. Return BenchmarkResult with SINGLE_STREAM scenario</span>
<span class="sd">        </span>
<span class="sd">        HINTS:</span>
<span class="sd">        - Use time.perf_counter() for precise timing</span>
<span class="sd">        - Use dataset[i % len(dataset)] to cycle through samples</span>
<span class="sd">        - Sort latencies for percentile calculations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">server</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span> <span class="n">target_qps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span> 
               <span class="n">duration</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">60.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BenchmarkResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run server benchmark scenario with Poisson-distributed queries.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement server benchmarking.</span>
<span class="sd">        </span>
<span class="sd">        STEP-BY-STEP:</span>
<span class="sd">        1. Calculate inter-arrival time = 1.0 / target_qps</span>
<span class="sd">        2. Run for specified duration:</span>
<span class="sd">           a. Wait for next query arrival (Poisson distribution)</span>
<span class="sd">           b. Get sample from dataset</span>
<span class="sd">           c. Record start time</span>
<span class="sd">           d. Run model</span>
<span class="sd">           e. Record end time and latency</span>
<span class="sd">        3. Calculate actual QPS = total_queries / duration</span>
<span class="sd">        4. Return results</span>
<span class="sd">        </span>
<span class="sd">        HINTS:</span>
<span class="sd">        - Use np.random.exponential(inter_arrival_time) for Poisson</span>
<span class="sd">        - Track both query arrival times and completion times</span>
<span class="sd">        - Server scenario cares about sustained throughput</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">offline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BenchmarkResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run offline benchmark scenario with batch processing.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement offline benchmarking.</span>
<span class="sd">        </span>
<span class="sd">        STEP-BY-STEP:</span>
<span class="sd">        1. Group dataset into batches of batch_size</span>
<span class="sd">        2. For each batch:</span>
<span class="sd">           a. Record start time</span>
<span class="sd">           b. Run model on entire batch</span>
<span class="sd">           c. Record end time</span>
<span class="sd">           d. Calculate batch latency</span>
<span class="sd">        3. Calculate total throughput = total_samples / total_time</span>
<span class="sd">        4. Return results</span>
<span class="sd">        </span>
<span class="sd">        HINTS:</span>
<span class="sd">        - Process data in batches for efficiency</span>
<span class="sd">        - Measure total time for all batches</span>
<span class="sd">        - Offline cares about maximum throughput</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="unit-test-benchmark-scenarios">
<h3>ğŸ§ª Unit Test: Benchmark Scenarios<a class="headerlink" href="#unit-test-benchmark-scenarios" title="Permalink to this heading">#</a></h3>
<p>Letâ€™s test our benchmark scenarios with a simple mock model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_benchmark_scenarios</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test that our benchmark scenarios work correctly.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸ”¬ Unit Test: Benchmark Scenarios...&quot;</span><span class="p">)</span>
    
    <span class="c1"># Create a simple mock model and dataset</span>
    <span class="k">def</span> <span class="nf">mock_model</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
        <span class="c1"># Simulate some processing time</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># 1ms processing</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)}</span>
    
    <span class="n">mock_dataset</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
    
    <span class="c1"># Test scenarios</span>
    <span class="n">scenarios</span> <span class="o">=</span> <span class="n">BenchmarkScenarios</span><span class="p">()</span>
    
    <span class="c1"># Test single-stream</span>
    <span class="n">single_result</span> <span class="o">=</span> <span class="n">scenarios</span><span class="o">.</span><span class="n">single_stream</span><span class="p">(</span><span class="n">mock_model</span><span class="p">,</span> <span class="n">mock_dataset</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">single_result</span><span class="o">.</span><span class="n">scenario</span> <span class="o">==</span> <span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">SINGLE_STREAM</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">single_result</span><span class="o">.</span><span class="n">latencies</span><span class="p">)</span> <span class="o">==</span> <span class="mi">10</span>
    <span class="k">assert</span> <span class="n">single_result</span><span class="o">.</span><span class="n">throughput</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Single-stream: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">single_result</span><span class="o">.</span><span class="n">latencies</span><span class="p">)</span><span class="si">}</span><span class="s2"> measurements&quot;</span><span class="p">)</span>
    
    <span class="c1"># Test server (short duration for testing)</span>
    <span class="n">server_result</span> <span class="o">=</span> <span class="n">scenarios</span><span class="o">.</span><span class="n">server</span><span class="p">(</span><span class="n">mock_model</span><span class="p">,</span> <span class="n">mock_dataset</span><span class="p">,</span> <span class="n">target_qps</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">server_result</span><span class="o">.</span><span class="n">scenario</span> <span class="o">==</span> <span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">SERVER</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">server_result</span><span class="o">.</span><span class="n">latencies</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">server_result</span><span class="o">.</span><span class="n">throughput</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Server: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">server_result</span><span class="o">.</span><span class="n">latencies</span><span class="p">)</span><span class="si">}</span><span class="s2"> queries processed&quot;</span><span class="p">)</span>
    
    <span class="c1"># Test offline</span>
    <span class="n">offline_result</span> <span class="o">=</span> <span class="n">scenarios</span><span class="o">.</span><span class="n">offline</span><span class="p">(</span><span class="n">mock_model</span><span class="p">,</span> <span class="n">mock_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">offline_result</span><span class="o">.</span><span class="n">scenario</span> <span class="o">==</span> <span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">OFFLINE</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">offline_result</span><span class="o">.</span><span class="n">latencies</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">offline_result</span><span class="o">.</span><span class="n">throughput</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Offline: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">offline_result</span><span class="o">.</span><span class="n">latencies</span><span class="p">)</span><span class="si">}</span><span class="s2"> batches processed&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… All benchmark scenarios working correctly!&quot;</span><span class="p">)</span>

<span class="c1"># Run the test</span>
<span class="n">test_benchmark_scenarios</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-3-statistical-validation-ensuring-meaningful-results">
<h2>Step 3: Statistical Validation - Ensuring Meaningful Results<a class="headerlink" href="#step-3-statistical-validation-ensuring-meaningful-results" title="Permalink to this heading">#</a></h2>
<section id="the-confidence-problem">
<h3>The Confidence Problem<a class="headerlink" href="#the-confidence-problem" title="Permalink to this heading">#</a></h3>
<p>How do we know if one model is actually better than another?</p>
</section>
<section id="statistical-testing-for-ml">
<h3>Statistical Testing for ML<a class="headerlink" href="#statistical-testing-for-ml" title="Permalink to this heading">#</a></h3>
<p>We need to test the null hypothesis: â€œThere is no significant difference between modelsâ€</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| export</span>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">StatisticalValidation</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Results from statistical validation&quot;&quot;&quot;</span>
    <span class="n">is_significant</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">p_value</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">effect_size</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">confidence_interval</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>
    <span class="n">recommendation</span><span class="p">:</span> <span class="nb">str</span>

<span class="c1">#| export</span>
<span class="k">class</span> <span class="nc">StatisticalValidator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validates benchmark results using proper statistical methods.</span>
<span class="sd">    </span>
<span class="sd">    TODO: Implement statistical validation for benchmark results.</span>
<span class="sd">    </span>
<span class="sd">    UNDERSTANDING STATISTICAL TESTING:</span>
<span class="sd">    1. Null hypothesis: No difference between models</span>
<span class="sd">    2. T-test: Compare means of two groups</span>
<span class="sd">    3. P-value: Probability of seeing this difference by chance</span>
<span class="sd">    4. Effect size: Magnitude of the difference</span>
<span class="sd">    5. Confidence interval: Range of likely true values</span>
<span class="sd">    </span>
<span class="sd">    IMPLEMENTATION APPROACH:</span>
<span class="sd">    1. Calculate basic statistics (mean, std, n)</span>
<span class="sd">    2. Perform t-test to get p-value</span>
<span class="sd">    3. Calculate effect size (Cohen&#39;s d)</span>
<span class="sd">    4. Calculate confidence interval</span>
<span class="sd">    5. Provide clear recommendation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">confidence_level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">confidence_level</span> <span class="o">=</span> <span class="n">confidence_level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">confidence_level</span>
    
    <span class="k">def</span> <span class="nf">validate_comparison</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results_a</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">results_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">StatisticalValidation</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compare two sets of benchmark results statistically.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement statistical comparison.</span>
<span class="sd">        </span>
<span class="sd">        STEP-BY-STEP:</span>
<span class="sd">        1. Calculate basic statistics for both groups</span>
<span class="sd">        2. Perform two-sample t-test</span>
<span class="sd">        3. Calculate effect size (Cohen&#39;s d)</span>
<span class="sd">        4. Calculate confidence interval for the difference</span>
<span class="sd">        5. Generate recommendation based on results</span>
<span class="sd">        </span>
<span class="sd">        HINTS:</span>
<span class="sd">        - Use scipy.stats.ttest_ind for t-test (or implement manually)</span>
<span class="sd">        - Cohen&#39;s d = (mean_a - mean_b) / pooled_std</span>
<span class="sd">        - CI = difference Â± (critical_value * standard_error)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">validate_benchmark_result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="n">BenchmarkResult</span><span class="p">,</span> 
                                 <span class="n">min_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">StatisticalValidation</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Validate that a benchmark result has sufficient statistical power.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement validation for single benchmark result.</span>
<span class="sd">        </span>
<span class="sd">        STEP-BY-STEP:</span>
<span class="sd">        1. Check if we have enough samples</span>
<span class="sd">        2. Calculate confidence interval for the metric</span>
<span class="sd">        3. Check for common pitfalls (outliers, etc.)</span>
<span class="sd">        4. Provide recommendations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="unit-test-statistical-validation">
<h3>ğŸ§ª Unit Test: Statistical Validation<a class="headerlink" href="#unit-test-statistical-validation" title="Permalink to this heading">#</a></h3>
<p>Letâ€™s test our statistical validation with simulated data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_statistical_validation</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test statistical validation functionality.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸ”¬ Unit Test: Statistical Validation...&quot;</span><span class="p">)</span>
    
    <span class="n">validator</span> <span class="o">=</span> <span class="n">StatisticalValidator</span><span class="p">(</span><span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
    
    <span class="c1"># Test 1: No significant difference</span>
    <span class="n">results_a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
    <span class="n">results_b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
    
    <span class="n">validation</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">validate_comparison</span><span class="p">(</span><span class="n">results_a</span><span class="p">,</span> <span class="n">results_b</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… No difference test: significant=</span><span class="si">{</span><span class="n">validation</span><span class="o">.</span><span class="n">is_significant</span><span class="si">}</span><span class="s2">, p=</span><span class="si">{</span><span class="n">validation</span><span class="o">.</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Test 2: Clear significant difference</span>
    <span class="n">results_a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
    <span class="n">results_b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>
    
    <span class="n">validation</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">validate_comparison</span><span class="p">(</span><span class="n">results_a</span><span class="p">,</span> <span class="n">results_b</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Clear difference test: significant=</span><span class="si">{</span><span class="n">validation</span><span class="o">.</span><span class="n">is_significant</span><span class="si">}</span><span class="s2">, p=</span><span class="si">{</span><span class="n">validation</span><span class="o">.</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Effect size: </span><span class="si">{</span><span class="n">validation</span><span class="o">.</span><span class="n">effect_size</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Recommendation: </span><span class="si">{</span><span class="n">validation</span><span class="o">.</span><span class="n">recommendation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Test 3: Single result validation</span>
    <span class="n">mock_result</span> <span class="o">=</span> <span class="n">BenchmarkResult</span><span class="p">(</span>
        <span class="n">scenario</span><span class="o">=</span><span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">SINGLE_STREAM</span><span class="p">,</span>
        <span class="n">latencies</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">)],</span>
        <span class="n">throughput</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">accuracy</span><span class="o">=</span><span class="mf">0.95</span>
    <span class="p">)</span>
    
    <span class="n">validation</span> <span class="o">=</span> <span class="n">validator</span><span class="o">.</span><span class="n">validate_benchmark_result</span><span class="p">(</span><span class="n">mock_result</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Single result validation: </span><span class="si">{</span><span class="n">validation</span><span class="o">.</span><span class="n">recommendation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Confidence interval: (</span><span class="si">{</span><span class="n">validation</span><span class="o">.</span><span class="n">confidence_interval</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">validation</span><span class="o">.</span><span class="n">confidence_interval</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Statistical validation tests passed!&quot;</span><span class="p">)</span>

<span class="c1"># Run the test</span>
<span class="n">test_statistical_validation</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-4-the-tinytorchperf-framework-putting-it-all-together">
<h2>Step 4: The TinyTorchPerf Framework - Putting It All Together<a class="headerlink" href="#step-4-the-tinytorchperf-framework-putting-it-all-together" title="Permalink to this heading">#</a></h2>
<section id="the-complete-mlperf-inspired-framework">
<h3>The Complete MLPerf-Inspired Framework<a class="headerlink" href="#the-complete-mlperf-inspired-framework" title="Permalink to this heading">#</a></h3>
<p>Now we combine all components into a professional benchmarking framework.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| export</span>
<span class="k">class</span> <span class="nc">TinyTorchPerf</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Complete MLPerf-inspired benchmarking framework for TinyTorch.</span>
<span class="sd">    </span>
<span class="sd">    TODO: Implement the complete benchmarking framework.</span>
<span class="sd">    </span>
<span class="sd">    UNDERSTANDING THE FRAMEWORK:</span>
<span class="sd">    1. Combines all benchmark scenarios</span>
<span class="sd">    2. Integrates statistical validation</span>
<span class="sd">    3. Provides easy-to-use API</span>
<span class="sd">    4. Generates professional reports</span>
<span class="sd">    </span>
<span class="sd">    IMPLEMENTATION APPROACH:</span>
<span class="sd">    1. Initialize with model and dataset</span>
<span class="sd">    2. Provide methods for each scenario</span>
<span class="sd">    3. Include statistical validation</span>
<span class="sd">    4. Generate comprehensive reports</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scenarios</span> <span class="o">=</span> <span class="n">BenchmarkScenarios</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validator</span> <span class="o">=</span> <span class="n">StatisticalValidator</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the model to benchmark.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    
    <span class="k">def</span> <span class="nf">set_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">List</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the dataset for benchmarking.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span>
    
    <span class="k">def</span> <span class="nf">run_single_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_queries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BenchmarkResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run single-stream benchmark.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement single-stream benchmark with validation.</span>
<span class="sd">        </span>
<span class="sd">        STEP-BY-STEP:</span>
<span class="sd">        1. Check that model and dataset are set</span>
<span class="sd">        2. Run single-stream scenario</span>
<span class="sd">        3. Validate results statistically</span>
<span class="sd">        4. Store results</span>
<span class="sd">        5. Return result</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">run_server</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_qps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">duration</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">60.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BenchmarkResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run server benchmark.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement server benchmark with validation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">run_offline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BenchmarkResult</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run offline benchmark.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement offline benchmark with validation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">run_all_scenarios</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quick_test</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">BenchmarkResult</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run all benchmark scenarios.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement comprehensive benchmarking.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">compare_models</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_a</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">model_b</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> 
                      <span class="n">scenario</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;single_stream&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">StatisticalValidation</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compare two models statistically.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement model comparison.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">generate_report</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate a comprehensive benchmark report.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement professional report generation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="unit-test-tinytorchperf-framework">
<h3>ğŸ§ª Unit Test: TinyTorchPerf Framework<a class="headerlink" href="#unit-test-tinytorchperf-framework" title="Permalink to this heading">#</a></h3>
<p>Letâ€™s test our complete benchmarking framework.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_tinytorch_perf</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test the complete TinyTorchPerf framework.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸ”¬ Unit Test: TinyTorchPerf Framework...&quot;</span><span class="p">)</span>
    
    <span class="c1"># Create test model and dataset</span>
    <span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># Simulate processing</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">)}</span>
    
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)]</span>
    
    <span class="c1"># Test the framework</span>
    <span class="n">benchmark</span> <span class="o">=</span> <span class="n">TinyTorchPerf</span><span class="p">()</span>
    <span class="n">benchmark</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">test_model</span><span class="p">)</span>
    <span class="n">benchmark</span><span class="o">.</span><span class="n">set_dataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
    
    <span class="c1"># Test individual scenarios</span>
    <span class="n">single_result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">run_single_stream</span><span class="p">(</span><span class="n">num_queries</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">single_result</span><span class="o">.</span><span class="n">scenario</span> <span class="o">==</span> <span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">SINGLE_STREAM</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Single-stream: </span><span class="si">{</span><span class="n">single_result</span><span class="o">.</span><span class="n">throughput</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> samples/sec&quot;</span><span class="p">)</span>
    
    <span class="n">server_result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">run_server</span><span class="p">(</span><span class="n">target_qps</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">server_result</span><span class="o">.</span><span class="n">scenario</span> <span class="o">==</span> <span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">SERVER</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Server: </span><span class="si">{</span><span class="n">server_result</span><span class="o">.</span><span class="n">throughput</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> QPS&quot;</span><span class="p">)</span>
    
    <span class="n">offline_result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">run_offline</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">offline_result</span><span class="o">.</span><span class="n">scenario</span> <span class="o">==</span> <span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">OFFLINE</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Offline: </span><span class="si">{</span><span class="n">offline_result</span><span class="o">.</span><span class="n">throughput</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> samples/sec&quot;</span><span class="p">)</span>
    
    <span class="c1"># Test comprehensive benchmarking</span>
    <span class="n">all_results</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">run_all_scenarios</span><span class="p">(</span><span class="n">quick_test</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… All scenarios: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">all_results</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Test model comparison</span>
    <span class="k">def</span> <span class="nf">slower_model</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.002</span><span class="p">)</span>  <span class="c1"># Twice as slow</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">)}</span>
    
    <span class="n">comparison</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">compare_models</span><span class="p">(</span><span class="n">test_model</span><span class="p">,</span> <span class="n">slower_model</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Model comparison: </span><span class="si">{</span><span class="n">comparison</span><span class="o">.</span><span class="n">recommendation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Test report generation</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">generate_report</span><span class="p">()</span>
    <span class="k">assert</span> <span class="s2">&quot;TinyTorch Benchmark Report&quot;</span> <span class="ow">in</span> <span class="n">report</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Report generation working&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Complete TinyTorchPerf framework working!&quot;</span><span class="p">)</span>

<span class="c1"># Run the test</span>
<span class="n">test_tinytorch_perf</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-5-professional-reporting-project-ready-results">
<h2>Step 5: Professional Reporting - Project-Ready Results<a class="headerlink" href="#step-5-professional-reporting-project-ready-results" title="Permalink to this heading">#</a></h2>
<section id="why-professional-reports-matter">
<h3>Why Professional Reports Matter<a class="headerlink" href="#why-professional-reports-matter" title="Permalink to this heading">#</a></h3>
<p>Your ML projects need:</p>
<ul class="simple">
<li><p><strong>Clear performance metrics</strong> for presentations</p></li>
<li><p><strong>Statistical validation</strong> for credibility</p></li>
<li><p><strong>Comparison baselines</strong> for context</p></li>
<li><p><strong>Professional formatting</strong> for academic/industry standards</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#| export</span>
<span class="k">class</span> <span class="nc">PerformanceReporter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates professional performance reports for ML projects.</span>
<span class="sd">    </span>
<span class="sd">    TODO: Implement professional report generation.</span>
<span class="sd">    </span>
<span class="sd">    UNDERSTANDING PROFESSIONAL REPORTS:</span>
<span class="sd">    1. Executive summary with key metrics</span>
<span class="sd">    2. Detailed methodology section</span>
<span class="sd">    3. Statistical validation results</span>
<span class="sd">    4. Comparison with baselines</span>
<span class="sd">    5. Recommendations for improvement</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reports</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">generate_project_report</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">benchmark_results</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">BenchmarkResult</span><span class="p">],</span> 
                               <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;TinyTorch Model&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate a professional performance report for ML projects.</span>
<span class="sd">        </span>
<span class="sd">        TODO: Implement project report generation.</span>
<span class="sd">        </span>
<span class="sd">        STEP-BY-STEP:</span>
<span class="sd">        1. Create executive summary</span>
<span class="sd">        2. Add methodology section</span>
<span class="sd">        3. Present detailed results</span>
<span class="sd">        4. Include statistical validation</span>
<span class="sd">        5. Add recommendations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">### BEGIN SOLUTION</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="c1">### END SOLUTION</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student implementation required&quot;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">save_report</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">report</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;benchmark_report.md&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save report to file.&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ğŸ“„ Report saved to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="unit-test-performance-reporter">
<h3>ğŸ§ª Unit Test: Performance Reporter<a class="headerlink" href="#unit-test-performance-reporter" title="Permalink to this heading">#</a></h3>
<p>Letâ€™s test our professional reporting system.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_performance_reporter</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test the performance reporter.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸ”¬ Unit Test: Performance Reporter...&quot;</span><span class="p">)</span>
    
    <span class="c1"># Create mock benchmark results</span>
    <span class="n">mock_results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;single_stream&#39;</span><span class="p">:</span> <span class="n">BenchmarkResult</span><span class="p">(</span>
            <span class="n">scenario</span><span class="o">=</span><span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">SINGLE_STREAM</span><span class="p">,</span>
            <span class="n">latencies</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span> <span class="o">+</span> <span class="mf">0.002</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)],</span>
            <span class="n">throughput</span><span class="o">=</span><span class="mf">95.0</span><span class="p">,</span>
            <span class="n">accuracy</span><span class="o">=</span><span class="mf">0.942</span>
        <span class="p">),</span>
        <span class="s1">&#39;server&#39;</span><span class="p">:</span> <span class="n">BenchmarkResult</span><span class="p">(</span>
            <span class="n">scenario</span><span class="o">=</span><span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">SERVER</span><span class="p">,</span>
            <span class="n">latencies</span><span class="o">=</span><span class="p">[</span><span class="mf">0.012</span> <span class="o">+</span> <span class="mf">0.003</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">150</span><span class="p">)],</span>
            <span class="n">throughput</span><span class="o">=</span><span class="mf">87.0</span><span class="p">,</span>
            <span class="n">accuracy</span><span class="o">=</span><span class="mf">0.938</span>
        <span class="p">),</span>
        <span class="s1">&#39;offline&#39;</span><span class="p">:</span> <span class="n">BenchmarkResult</span><span class="p">(</span>
            <span class="n">scenario</span><span class="o">=</span><span class="n">BenchmarkScenario</span><span class="o">.</span><span class="n">OFFLINE</span><span class="p">,</span>
            <span class="n">latencies</span><span class="o">=</span><span class="p">[</span><span class="mf">0.008</span> <span class="o">+</span> <span class="mf">0.001</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)],</span>
            <span class="n">throughput</span><span class="o">=</span><span class="mf">120.0</span><span class="p">,</span>
            <span class="n">accuracy</span><span class="o">=</span><span class="mf">0.945</span>
        <span class="p">)</span>
    <span class="p">}</span>
    
    <span class="c1"># Test report generation</span>
    <span class="n">reporter</span> <span class="o">=</span> <span class="n">PerformanceReporter</span><span class="p">()</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">reporter</span><span class="o">.</span><span class="n">generate_project_report</span><span class="p">(</span><span class="n">mock_results</span><span class="p">,</span> <span class="s2">&quot;My Project Model&quot;</span><span class="p">)</span>
    
    <span class="c1"># Verify report content</span>
    <span class="k">assert</span> <span class="s2">&quot;Performance Report&quot;</span> <span class="ow">in</span> <span class="n">report</span>
    <span class="k">assert</span> <span class="s2">&quot;Executive Summary&quot;</span> <span class="ow">in</span> <span class="n">report</span>
    <span class="k">assert</span> <span class="s2">&quot;Methodology&quot;</span> <span class="ow">in</span> <span class="n">report</span>
    <span class="k">assert</span> <span class="s2">&quot;Detailed Results&quot;</span> <span class="ow">in</span> <span class="n">report</span>
    <span class="k">assert</span> <span class="s2">&quot;Statistical Validation&quot;</span> <span class="ow">in</span> <span class="n">report</span>
    <span class="k">assert</span> <span class="s2">&quot;Recommendations&quot;</span> <span class="ow">in</span> <span class="n">report</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Report generated successfully&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Report length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">report</span><span class="p">)</span><span class="si">}</span><span class="s2"> characters&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Contains all required sections&quot;</span><span class="p">)</span>
    
    <span class="c1"># Test saving</span>
    <span class="n">reporter</span><span class="o">.</span><span class="n">save_report</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s2">&quot;test_report.md&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Report saving working&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Performance reporter tests passed!&quot;</span><span class="p">)</span>

<span class="c1"># Run the test</span>
<span class="n">test_performance_reporter</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="comprehensive-integration-test">
<h2>Comprehensive Integration Test<a class="headerlink" href="#comprehensive-integration-test" title="Permalink to this heading">#</a></h2>
<p>Letâ€™s test everything together with a realistic TinyTorch model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_comprehensive_benchmarking</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test the complete benchmarking system with a realistic model.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸ”¬ Comprehensive Integration Test...&quot;</span><span class="p">)</span>
    
    <span class="c1"># Create a realistic TinyTorch model</span>
    <span class="k">def</span> <span class="nf">create_simple_model</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a simple classification model for testing.&quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
            <span class="c1"># Simulate a simple neural network</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>
            
            <span class="c1"># Layer 1: 10 -&gt; 5</span>
            <span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
            <span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
            <span class="n">h1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W1</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span>  <span class="c1"># ReLU</span>
            
            <span class="c1"># Layer 2: 5 -&gt; 3</span>
            <span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
            <span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">h1</span> <span class="o">@</span> <span class="n">W2</span> <span class="o">+</span> <span class="n">b2</span>
            
            <span class="c1"># Simulate some processing time</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>
            
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="n">output</span><span class="p">}</span>
        
        <span class="k">return</span> <span class="n">model</span>
    
    <span class="c1"># Create test dataset</span>
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
            <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="n">test_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    
    <span class="c1"># Test complete workflow</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_simple_model</span><span class="p">()</span>
    
    <span class="c1"># 1. Run comprehensive benchmarking</span>
    <span class="n">benchmark</span> <span class="o">=</span> <span class="n">TinyTorchPerf</span><span class="p">()</span>
    <span class="n">benchmark</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">benchmark</span><span class="o">.</span><span class="n">set_dataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸ“Š Running comprehensive benchmarking...&quot;</span><span class="p">)</span>
    <span class="n">all_results</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">run_all_scenarios</span><span class="p">(</span><span class="n">quick_test</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># 2. Generate professional report</span>
    <span class="n">reporter</span> <span class="o">=</span> <span class="n">PerformanceReporter</span><span class="p">()</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">reporter</span><span class="o">.</span><span class="n">generate_project_report</span><span class="p">(</span><span class="n">all_results</span><span class="p">,</span> <span class="s2">&quot;TinyTorch CNN Model&quot;</span><span class="p">)</span>
    
    <span class="c1"># 3. Validate results</span>
    <span class="k">for</span> <span class="n">scenario_name</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">all_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">assert</span> <span class="n">result</span><span class="o">.</span><span class="n">throughput</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scenario_name</span><span class="si">}</span><span class="s2"> should have positive throughput&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">latencies</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scenario_name</span><span class="si">}</span><span class="s2"> should have latency measurements&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… </span><span class="si">{</span><span class="n">scenario_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">throughput</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> samples/sec&quot;</span><span class="p">)</span>
    
    <span class="c1"># 4. Test model comparison</span>
    <span class="k">def</span> <span class="nf">create_slower_model</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a slower model for comparison.&quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>
            <span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
            <span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
            <span class="n">h1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span> <span class="o">@</span> <span class="n">W1</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span>
            
            <span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
            <span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">h1</span> <span class="o">@</span> <span class="n">W2</span> <span class="o">+</span> <span class="n">b2</span>
            
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.002</span><span class="p">)</span>  <span class="c1"># Slower</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;prediction&quot;</span><span class="p">:</span> <span class="n">output</span><span class="p">}</span>
        
        <span class="k">return</span> <span class="n">model</span>
    
    <span class="n">slower_model</span> <span class="o">=</span> <span class="n">create_slower_model</span><span class="p">()</span>
    <span class="n">comparison</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">compare_models</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">slower_model</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Model comparison: </span><span class="si">{</span><span class="n">comparison</span><span class="o">.</span><span class="n">recommendation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># 5. Test report quality</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">report</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">,</span> <span class="s2">&quot;Report should be comprehensive&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;âœ… Generated </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">report</span><span class="p">)</span><span class="si">}</span><span class="s2"> character report&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;âœ… Comprehensive integration test passed!&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ğŸ‰ Complete benchmarking system working!&quot;</span><span class="p">)</span>

<span class="c1"># Run the comprehensive test</span>
<span class="n">test_comprehensive_benchmarking</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="module-testing">
<h2>ğŸ§ª Module Testing<a class="headerlink" href="#module-testing" title="Permalink to this heading">#</a></h2>
<p>Time to test your implementation! This section uses TinyTorchâ€™s standardized testing framework to ensure your implementation works correctly.</p>
<p><strong>This testing section is locked</strong> - it provides consistent feedback across all modules and cannot be modified.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># =============================================================================</span>
<span class="c1"># STANDARDIZED MODULE TESTING - DO NOT MODIFY</span>
<span class="c1"># This cell is locked to ensure consistent testing across all TinyTorch modules</span>
<span class="c1"># =============================================================================</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tito.tools.testing</span> <span class="kn">import</span> <span class="n">run_module_tests_auto</span>
    
    <span class="c1"># Automatically discover and run all tests in this module</span>
    <span class="n">success</span> <span class="o">=</span> <span class="n">run_module_tests_auto</span><span class="p">(</span><span class="s2">&quot;Benchmarking&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="module-summary-systematic-ml-performance-evaluation">
<h2>ğŸ¯ Module Summary: Systematic ML Performance Evaluation<a class="headerlink" href="#module-summary-systematic-ml-performance-evaluation" title="Permalink to this heading">#</a></h2>
<section id="what-you-ve-built">
<h3>What Youâ€™ve Built<a class="headerlink" href="#what-you-ve-built" title="Permalink to this heading">#</a></h3>
<p>Youâ€™ve implemented a comprehensive MLPerf-inspired benchmarking framework:</p>
<ol class="arabic simple">
<li><p><strong>Benchmark Scenarios</strong>: Single-stream (latency), server (throughput), and offline (batch processing)</p></li>
<li><p><strong>Statistical Validation</strong>: Confidence intervals, significance testing, and effect size calculation</p></li>
<li><p><strong>MLPerf Architecture</strong>: Four-component system with load generator, model, dataset, and evaluation</p></li>
<li><p><strong>Professional Reporting</strong>: Generate conference-quality performance reports with proper methodology</p></li>
<li><p><strong>Model Comparison</strong>: Systematic comparison framework with statistical validation</p></li>
</ol>
</section>
<section id="key-insights">
<h3>Key Insights<a class="headerlink" href="#key-insights" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Systematic evaluation beats intuition</strong>: Proper benchmarking reveals true performance characteristics</p></li>
<li><p><strong>Statistics matter</strong>: Single measurements are meaningless; confidence intervals provide real insights</p></li>
<li><p><strong>Scenarios capture reality</strong>: Different use cases (mobile, server, batch) require different metrics</p></li>
<li><p><strong>Reproducibility is crucial</strong>: Others must be able to verify your results</p></li>
<li><p><strong>Professional presentation</strong>: Clear methodology and statistical validation build credibility</p></li>
</ul>
</section>
<section id="real-world-connections">
<h3>Real-World Connections<a class="headerlink" href="#real-world-connections" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>MLPerf</strong>: Uses identical four-component architecture and scenario patterns</p></li>
<li><p><strong>Production systems</strong>: A/B testing frameworks follow these statistical principles</p></li>
<li><p><strong>Research papers</strong>: Proper experimental methodology is required for publication</p></li>
<li><p><strong>ML engineering</strong>: Systematic evaluation prevents costly production mistakes</p></li>
<li><p><strong>Open source</strong>: Contributing benchmarks to libraries like PyTorch and TensorFlow</p></li>
</ul>
</section>
<section id="next-steps">
<h3>Next Steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">#</a></h3>
<p>In real ML systems, youâ€™d:</p>
<ol class="arabic simple">
<li><p><strong>GPU benchmarking</strong>: Extend to CUDA/OpenCL performance measurement</p></li>
<li><p><strong>Distributed evaluation</strong>: Scale benchmarking across multiple machines</p></li>
<li><p><strong>Continuous monitoring</strong>: Integrate with CI/CD pipelines for regression detection</p></li>
<li><p><strong>Domain-specific metrics</strong>: Develop specialized benchmarks for your problem domain</p></li>
<li><p><strong>Hardware optimization</strong>: Evaluate performance across different architectures</p></li>
</ol>
</section>
<section id="achievement-unlocked">
<h3>ğŸ† Achievement Unlocked<a class="headerlink" href="#achievement-unlocked" title="Permalink to this heading">#</a></h3>
<p>Youâ€™ve mastered systematic ML evaluation using industry-standard methodology. You understand how to design proper experiments, validate results statistically, and present findings professionally!</p>
<p><strong>Youâ€™ve completed the TinyTorch Benchmarking module!</strong> ğŸ‰</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="11-kernels.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Kernels</p>
      </div>
    </a>
    <a class="right-next"
       href="13-mlops.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">MLOps</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-this-code-lives-in-the-final-package">ğŸ“¦ Where This Code Lives in the Final Package</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-ml-benchmarking">What is ML Benchmarking?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-systematic-evaluation-problem">The Systematic Evaluation Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mlperf-architecture">The MLPerf Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-four-components">The Four Components</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-this-matters">Why This Matters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-examples">Real-World Examples</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-benchmark-scenarios-how-to-measure-performance">Step 1: Benchmark Scenarios - How to Measure Performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-three-standard-scenarios">The Three Standard Scenarios</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#single-stream-scenario">1. Single-Stream Scenario</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#server-scenario">2. Server Scenario</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#offline-scenario">3. Offline Scenario</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-foundation">Mathematical Foundation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-multiple-scenarios">Why Multiple Scenarios?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-statistical-validation-ensuring-meaningful-results">Step 2: Statistical Validation - Ensuring Meaningful Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-significance-problem">The Significance Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mlperf-solution">The MLPerf Solution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-statistical-concepts">Key Statistical Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-size-calculation">Sample Size Calculation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-test-benchmark-scenarios">ğŸ§ª Unit Test: Benchmark Scenarios</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-statistical-validation-ensuring-meaningful-results">Step 3: Statistical Validation - Ensuring Meaningful Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-confidence-problem">The Confidence Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-testing-for-ml">Statistical Testing for ML</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-test-statistical-validation">ğŸ§ª Unit Test: Statistical Validation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-the-tinytorchperf-framework-putting-it-all-together">Step 4: The TinyTorchPerf Framework - Putting It All Together</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-complete-mlperf-inspired-framework">The Complete MLPerf-Inspired Framework</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-test-tinytorchperf-framework">ğŸ§ª Unit Test: TinyTorchPerf Framework</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-professional-reporting-project-ready-results">Step 5: Professional Reporting - Project-Ready Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-professional-reports-matter">Why Professional Reports Matter</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unit-test-performance-reporter">ğŸ§ª Unit Test: Performance Reporter</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comprehensive-integration-test">Comprehensive Integration Test</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-testing">ğŸ§ª Module Testing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-summary-systematic-ml-performance-evaluation">ğŸ¯ Module Summary: Systematic ML Performance Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-you-ve-built">What Youâ€™ve Built</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-insights">Key Insights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#real-world-connections">Real-World Connections</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#achievement-unlocked">ğŸ† Achievement Unlocked</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By TinyTorch Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>