# üìö Additional Learning Resources

**Complement your TinyTorch journey with these carefully selected resources.**

While TinyTorch teaches you to build complete ML systems from scratch, these resources provide broader context, alternative perspectives, and production tools.

---

## üéì **Academic Courses**

### **Machine Learning Systems**
- **[CS 329S: Machine Learning Systems Design](https://stanford-cs329s.github.io/)** (Stanford)  
  *Production ML systems, infrastructure, and deployment at scale*

- **[CS 6.S965: TinyML and Efficient Deep Learning](https://hanlab.mit.edu/courses/2024-fall-65940)** (MIT)  
  *Edge computing, model compression, and efficient ML algorithms*

- **[CS 249r: Tiny Machine Learning](https://sites.google.com/g.harvard.edu/tinyml/home)** (Harvard)  
  *TinyML systems, edge AI, and resource-constrained machine learning*

### **Deep Learning Foundations**
- **[CS 231n: Convolutional Neural Networks](http://cs231n.stanford.edu/)** (Stanford)  
  *Computer vision and CNN architectures - complements TinyTorch spatial modules*

- **[CS 224n: Natural Language Processing](http://web.stanford.edu/class/cs224n/)** (Stanford)  
  *NLP and transformers - perfect follow-up to TinyTorch attention module*

---

## üìñ **Recommended Books**

### **Systems & Engineering**
- **[Machine Learning Systems](https://mlsysbook.ai)** by Prof. Vijay Janapa Reddi (Harvard)  
  *Comprehensive systems perspective on ML engineering and optimization - the perfect companion to TinyTorch*

- **[Designing Machine Learning Systems](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/)** by Chip Huyen  
  *Production ML engineering, data pipelines, and system design*

- **[Machine Learning Engineering](https://www.mlebook.com/wiki/doku.php)** by Andriy Burkov  
  *End-to-end ML project lifecycle and best practices*

### **Implementation & Theory**
- **[Deep Learning](https://www.deeplearningbook.org/)** by Ian Goodfellow, Yoshua Bengio, Aaron Courville  
  *Mathematical foundations - the theory behind what you implement in TinyTorch*

- **[Hands-On Machine Learning](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/)** by Aur√©lien G√©ron  
  *Practical implementations using established frameworks*

---

## üõ†Ô∏è **Alternative Implementations**

**Different approaches to building ML systems from scratch - see how others tackle the same challenge:**

### **Minimal Frameworks**
- **[Micrograd](https://github.com/karpathy/micrograd)** by Andrej Karpathy  
  *Minimal autograd engine in 100 lines. **Micrograd shows you the math, TinyTorch shows you the systems.***

- **[Tinygrad](https://github.com/geohot/tinygrad)** by George Hotz  
  *Performance-focused educational framework. **Tinygrad optimizes for speed, TinyTorch optimizes for learning.***

- **[Neural Networks from Scratch](https://nnfs.io/)** by Harrison Kinsley  
  *Math-heavy implementation approach. **NNFS focuses on algorithms, TinyTorch focuses on systems engineering.***

---

## üè≠ **Production Internals**

### **Framework Deep Dives**
- **[PyTorch Internals](http://blog.ezyang.com/2019/05/pytorch-internals/)** by Edward Yang  
  *How PyTorch actually works under the hood - a great read as see what you built in TinyTorch corresponds to the real PyTorch*

- **[PyTorch Documentation: Extending PyTorch](https://pytorch.org/docs/stable/notes/extending.html)**  
  *Custom operators and autograd functions - apply your TinyTorch knowledge*

---

*Building ML systems from scratch gives you the implementation foundation most ML engineers lack. These resources help you apply that knowledge to broader systems and production environments.* üöÄ 