# üìö Additional Learning Resources

**Complement your TinyTorch journey with these carefully selected resources.**

While TinyTorch teaches you to build complete ML systems from scratch, these resources provide broader context, alternative perspectives, and production tools.

---

## üéì **Academic Courses**

### **Machine Learning Systems**
- **[CS 329S: Machine Learning Systems Design](https://stanford-cs329s.github.io/)** (Stanford)  
  *Production ML systems, infrastructure, and deployment at scale*

- **[CS 6.S965: TinyML and Efficient Deep Learning](https://hanlab.mit.edu/courses/2024-fall-65940)** (MIT)  
  *Edge computing, model compression, and efficient ML algorithms*

- **[CS 249r: Tiny Machine Learning](https://sites.google.com/g.harvard.edu/tinyml/home)** (Harvard)  
  *TinyML systems, edge AI, and resource-constrained machine learning*

### **Deep Learning Foundations**
- **[CS 231n: Convolutional Neural Networks](http://cs231n.stanford.edu/)** (Stanford)  
  *Computer vision and CNN architectures - complements TinyTorch spatial modules*

- **[CS 224n: Natural Language Processing](http://web.stanford.edu/class/cs224n/)** (Stanford)  
  *NLP and transformers - perfect follow-up to TinyTorch attention module*

---

## üìñ **Recommended Books**

### **Systems & Engineering**
- **[Machine Learning Systems](https://mlsysbook.ai)** by Prof. Vijay Janapa Reddi (Harvard)  
  *Comprehensive systems perspective on ML engineering and optimization - the perfect companion to TinyTorch*

- **[Designing Machine Learning Systems](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/)** by Chip Huyen  
  *Production ML engineering, data pipelines, and system design*

- **[Machine Learning Engineering](https://www.mlebook.com/wiki/doku.php)** by Andriy Burkov  
  *End-to-end ML project lifecycle and best practices*

### **Implementation & Theory**
- **[Deep Learning](https://www.deeplearningbook.org/)** by Ian Goodfellow, Yoshua Bengio, Aaron Courville  
  *Mathematical foundations - the theory behind what you implement in TinyTorch*

- **[Hands-On Machine Learning](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/)** by Aur√©lien G√©ron  
  *Practical implementations using established frameworks*

---

## üõ†Ô∏è **Alternative Implementations**

**Different approaches to building ML systems from scratch - see how others tackle the same challenge:**

### **Minimal Frameworks**
- **[Micrograd](https://github.com/karpathy/micrograd)** by Andrej Karpathy  
  *Minimal autograd engine in 100 lines. **Micrograd teaches engine parts, TinyTorch teaches you to design the whole vehicle and drive it.***

- **[Tinygrad](https://github.com/geohot/tinygrad)** by George Hotz  
  *Performance-focused educational framework. **Tinygrad optimizes for speed, TinyTorch optimizes for learning systems thinking.***

- **[Neural Networks from Scratch](https://nnfs.io/)** by Harrison Kinsley  
  *Math-heavy implementation approach. **NNFS teaches you the engine parts, TinyTorch teaches you to design the whole vehicle and drive it.***

---

## üè≠ **Production Tools & Platforms**

### **Framework Deep Dives**
- **[PyTorch Internals](http://blog.ezyang.com/2019/05/pytorch-internals/)** by Edward Yang  
  *How PyTorch actually works under the hood - see what you built in TinyTorch at production scale*

- **[PyTorch Documentation: Extending PyTorch](https://pytorch.org/docs/stable/notes/extending.html)**  
  *Custom operators and autograd functions - apply your TinyTorch knowledge*

### **MLOps & Production**
- **[Papers With Code](https://paperswithcode.com/)**  
  *Research papers with implementation code - apply your skills to reproduce results*

- **[MLOps Community](https://mlops.community/)**  
  *Production ML engineering discussions and best practices*

- **[Weights & Biases](https://wandb.ai/)**  
  *Experiment tracking and model management - scale your TinyTorch training*

---

## üåê **Learning Communities**

### **Technical Discussion**
- **[r/MachineLearning](https://www.reddit.com/r/MachineLearning/)**  
  *Research discussions and paper releases*

- **[The Gradient](https://thegradient.pub/)**  
  *Deep technical articles on ML research and systems*

- **[Distill.pub](https://distill.pub/)**  
  *Interactive explanations of ML concepts with beautiful visualizations*

---

## üéØ **Next Steps After TinyTorch**

### **Apply Your Skills**
1. **Reproduce Research**: Use your TinyTorch foundation to implement papers from scratch
2. **Contribute to Open Source**: PyTorch, TensorFlow, JAX - you now understand the internals
3. **Build Production Systems**: Apply MLOps principles from your final modules
4. **Optimize for Edge**: Use compression and kernel techniques for deployment

### **Advanced Specializations**
- **Distributed Training**: Scale your framework knowledge to multi-GPU systems
- **Compiler Design**: Build domain-specific languages for ML (JAX, Triton style)
- **Hardware Acceleration**: Custom kernels and specialized processors
- **Systems Research**: Novel architectures and training techniques

---

## üí° **How to Use These Resources**

```{admonition} üéØ Strategic Learning Path
:class: tip
**Parallel Learning**: Use these alongside TinyTorch modules for broader context

**Post-TinyTorch**: After completing the framework, dive into production systems

**Compare & Contrast**: Study alternative implementations to understand design trade-offs
```

**Remember**: You now have the implementation foundation that most ML engineers lack. These resources help you apply that knowledge to broader systems and production environments.

---

*Building ML systems from scratch gives you superpowers. These resources help you use them wisely.* üöÄ 