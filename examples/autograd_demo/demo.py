#!/usr/bin/env python3
"""
Automatic Differentiation with TinyTorch

Demonstrates how automatic differentiation works in YOUR TinyTorch,
showing gradient computation through complex computational graphs.

This is the magic that makes deep learning possible!
"""

import numpy as np
import tinytorch as tt
from tinytorch.core import Tensor
from tinytorch.core.autograd import Variable, backward


def simple_gradient_example():
    """Show basic gradient computation."""
    print("ğŸ“ Example 1: Simple Gradient")
    print("-" * 40)
    
    # Create variables that track gradients
    x = Variable(2.0, requires_grad=True)
    y = Variable(3.0, requires_grad=True)
    
    # Forward computation: z = x*y + x^2
    z = x * y + x ** 2
    
    print(f"x = {x.data}")
    print(f"y = {y.data}")
    print(f"z = x*y + x^2 = {z.data}")
    print()
    
    # Backward pass
    z.backward()
    
    print("Gradients after backward():")
    print(f"âˆ‚z/âˆ‚x = {x.grad}  (should be y + 2x = 3 + 4 = 7)")
    print(f"âˆ‚z/âˆ‚y = {y.grad}  (should be x = 2)")
    print()


def computational_graph_example():
    """Show gradients through a computational graph."""
    print("ğŸŒ³ Example 2: Computational Graph")
    print("-" * 40)
    
    # Build a more complex graph
    a = Variable(1.0, requires_grad=True)
    b = Variable(2.0, requires_grad=True)
    c = Variable(3.0, requires_grad=True)
    
    # Forward: d = (a + b) * c
    d = a + b
    e = d * c
    
    print("Computational graph:")
    print("  a = 1.0")
    print("  b = 2.0")  
    print("  c = 3.0")
    print("  d = a + b = 3.0")
    print("  e = d * c = 9.0")
    print()
    
    # Backward
    e.backward()
    
    print("Gradients:")
    print(f"âˆ‚e/âˆ‚a = {a.grad}  (flows through d)")
    print(f"âˆ‚e/âˆ‚b = {b.grad}  (flows through d)")
    print(f"âˆ‚e/âˆ‚c = {c.grad}  (direct multiplication)")
    print()


def neural_network_gradients():
    """Show gradients in a neural network layer."""
    print("ğŸ§  Example 3: Neural Network Layer")
    print("-" * 40)
    
    # Input and weights
    X = Variable(Tensor([[1.0, 2.0]]), requires_grad=True)
    W = Variable(Tensor([[0.5, -0.3], [0.2, 0.8]]), requires_grad=True)
    b = Variable(Tensor([0.1, 0.2]), requires_grad=True)
    
    print("Neural network layer: y = X @ W + b")
    print(f"Input X: {X.data}")
    print(f"Weights W:\n{W.data}")
    print(f"Bias b: {b.data}")
    print()
    
    # Forward pass
    y = X @ W + b
    print(f"Output y: {y.data}")
    
    # Define a simple loss (sum of outputs)
    loss = y.sum()
    print(f"Loss (sum): {loss.data}")
    print()
    
    # Backward pass
    loss.backward()
    
    print("Gradients for weight update:")
    print(f"âˆ‚L/âˆ‚W:\n{W.grad}")
    print(f"âˆ‚L/âˆ‚b: {b.grad}")
    print(f"âˆ‚L/âˆ‚X: {X.grad}")
    print()


def gradient_descent_visualization():
    """Visualize gradient descent optimization."""
    print("ğŸ“‰ Example 4: Gradient Descent")
    print("-" * 40)
    
    # Optimize: minimize f(x) = (x - 3)^2
    x = Variable(0.0, requires_grad=True)
    learning_rate = 0.1
    
    print("Minimizing f(x) = (x - 3)^2")
    print("Starting at x = 0.0")
    print()
    
    history = []
    for step in range(10):
        # Forward: compute loss
        loss = (x - 3.0) ** 2
        
        # Backward: compute gradient
        x.zero_grad()  # Clear previous gradients
        loss.backward()
        
        # Update: gradient descent
        x.data = x.data - learning_rate * x.grad
        history.append((x.data, loss.data))
        
        if step % 2 == 0:
            print(f"Step {step}: x = {x.data:.3f}, f(x) = {loss.data:.3f}, grad = {x.grad:.3f}")
    
    print()
    print(f"Converged to x = {x.data:.3f} (optimal is 3.0)")
    print()


def chain_rule_demonstration():
    """Demonstrate the chain rule in action."""
    print("â›“ï¸ Example 5: Chain Rule")
    print("-" * 40)
    
    x = Variable(2.0, requires_grad=True)
    
    # Composite function: f(g(h(x)))
    # h(x) = x^2
    # g(h) = h + 1  
    # f(g) = sqrt(g)
    
    h = x ** 2          # h = 4
    g = h + 1           # g = 5
    f = g ** 0.5        # f = sqrt(5) â‰ˆ 2.236
    
    print("Composite function: f(g(h(x))) = sqrt(x^2 + 1)")
    print(f"x = {x.data}")
    print(f"h = x^2 = {h.data}")
    print(f"g = h + 1 = {g.data}")
    print(f"f = sqrt(g) = {f.data:.3f}")
    print()
    
    # Backward uses chain rule
    f.backward()
    
    print("Chain rule gradient:")
    print(f"âˆ‚f/âˆ‚x = âˆ‚f/âˆ‚g Â· âˆ‚g/âˆ‚h Â· âˆ‚h/âˆ‚x")
    print(f"      = (1/2âˆšg) Â· 1 Â· 2x")
    print(f"      = x/âˆš(x^2 + 1)")
    print(f"      = {x.grad:.3f}")
    
    # Manual computation for verification
    manual_grad = x.data / np.sqrt(x.data**2 + 1)
    print(f"Manual: {manual_grad:.3f} âœ“")
    print()


def main():
    print("=" * 50)
    print("ğŸ”¬ Automatic Differentiation with TinyTorch")
    print("=" * 50)
    print()
    print("This demonstrates the autograd engine you built!")
    print("Every modern deep learning framework needs this.")
    print()
    
    # Run all examples
    simple_gradient_example()
    computational_graph_example()
    neural_network_gradients()
    gradient_descent_visualization()
    chain_rule_demonstration()
    
    print("=" * 50)
    print("ğŸ¯ Key Takeaways:")
    print("-" * 50)
    print("âœ… Automatic differentiation computes exact gradients")
    print("âœ… Chain rule enables gradients through deep networks")
    print("âœ… Computational graphs track operations for backprop")
    print("âœ… This is the foundation of all deep learning!")
    print()
    print("ğŸ‰ Your autograd engine makes training possible!")
    
    return True


if __name__ == "__main__":
    success = main()