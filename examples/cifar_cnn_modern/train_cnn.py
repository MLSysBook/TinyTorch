#!/usr/bin/env python3
"""
CIFAR-10 CNN (Modern) - Convolutional Revolution
===============================================

üìö HISTORICAL CONTEXT:
Convolutional Neural Networks revolutionized computer vision by exploiting spatial
structure in images. Unlike MLPs that flatten images (losing spatial relationships),
CNNs preserve spatial hierarchies through local connectivity and weight sharing,
enabling recognition of complex patterns in natural images.

üéØ WHAT YOU'RE BUILDING:
Using YOUR TinyTorch implementations, you'll build a CNN that achieves 65%+ accuracy
on CIFAR-10 natural images - proving YOUR spatial modules can extract hierarchical
features from real-world photographs!

‚úÖ REQUIRED MODULES (Run after Module 10):
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
  Module 02 (Tensor)        : YOUR data structure with autodiff
  Module 03 (Activations)   : YOUR ReLU for feature extraction
  Module 04 (Layers)        : YOUR Linear layers for classification
  Module 05 (Losses)        : YOUR CrossEntropy loss
  Module 07 (Optimizers)    : YOUR Adam optimizer
  Module 08 (Training)      : YOUR training loops
  Module 09 (Spatial)       : YOUR Conv2D, MaxPool2D, Flatten
  Module 10 (DataLoader)    : YOUR CIFAR10Dataset and batching
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üèóÔ∏è ARCHITECTURE (Hierarchical Feature Extraction):
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Input Image ‚îÇ  ‚îÇ Conv2D  ‚îÇ  ‚îÇ MaxPool ‚îÇ  ‚îÇ Conv2D  ‚îÇ  ‚îÇ MaxPool ‚îÇ
    ‚îÇ 32√ó32√ó3 RGB ‚îÇ‚îÄ‚ñ∂‚îÇ 3‚Üí32    ‚îÇ‚îÄ‚ñ∂‚îÇ  2√ó2    ‚îÇ‚îÄ‚ñ∂‚îÇ 32‚Üí64   ‚îÇ‚îÄ‚ñ∂‚îÇ  2√ó2    ‚îÇ
    ‚îÇ   Pixels    ‚îÇ  ‚îÇ YOUR M9 ‚îÇ  ‚îÇ YOUR M9 ‚îÇ  ‚îÇ YOUR M9 ‚îÇ  ‚îÇ YOUR M9 ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚Üì                          ‚Üì
                    Edge Detection             Shape Detection
                    
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ Flatten ‚Üí Linear ‚Üí Linear ‚Üí 10  ‚îÇ
                     ‚îÇ YOUR M9    YOUR M4  YOUR M4     ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     Object Recognition ‚Üí Classification

üîç CIFAR-10 DATASET - REAL NATURAL IMAGES:

CIFAR-10 contains 60,000 32√ó32 color images in 10 classes:

    Sample Images:                    Feature Hierarchy YOUR CNN Learns:
    
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     Layer 1 (Conv 3‚Üí32):
    ‚îÇ ‚úàÔ∏è Plane  ‚îÇ                     ‚Ä¢ Edge detectors
    ‚îÇ[Sky blue ]‚îÇ                     ‚Ä¢ Color gradients
    ‚îÇ[White    ]‚îÇ                     ‚Ä¢ Simple textures
    ‚îÇ[Wings    ]‚îÇ                     
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     Layer 2 (Conv 32‚Üí64):
                                      ‚Ä¢ Object parts
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚Ä¢ Complex patterns
    ‚îÇ üöó Car   ‚îÇ                     ‚Ä¢ Spatial relationships
    ‚îÇ[Red body ]‚îÇ                     
    ‚îÇ[Wheels   ]‚îÇ                     Output Layer:
    ‚îÇ[Windows  ]‚îÇ                     ‚Ä¢ Complete objects
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚Ä¢ Class probabilities

    Classes: plane, car, bird, cat, deer, dog, frog, horse, ship, truck

    Why CNNs Excel at Natural Images:
    ‚Ä¢ LOCAL CONNECTIVITY: Pixels near each other are related
    ‚Ä¢ WEIGHT SHARING: Same filter detects patterns everywhere
    ‚Ä¢ HIERARCHICAL LEARNING: Edges ‚Üí Shapes ‚Üí Objects
    ‚Ä¢ TRANSLATION INVARIANCE: Detects cat anywhere in image

üìä EXPECTED PERFORMANCE:
- Dataset: 50,000 training images, 10,000 test images
- Training time: 3-5 minutes (demonstration mode)
- Expected accuracy: 65%+ (with YOUR simple CNN!)
- Parameters: ~600K (mostly in conv layers)
"""

import sys
import os
import numpy as np
import argparse
import time

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

# Import TinyTorch components YOU BUILT!
from tinytorch.core.tensor import Tensor              # Module 02: YOU built this!
from tinytorch.core.layers import Linear             # Module 04: YOU built this!
from tinytorch.core.activations import ReLU, Softmax  # Module 03: YOU built this!
from tinytorch.core.spatial import Conv2D, MaxPool2D  # Module 09: YOU built this!
from tinytorch.core.losses import CrossEntropyLoss    # Module 05: YOU built this!
from tinytorch.core.optimizers import Adam            # Module 07: YOU built this!
# DataLoader would normally be imported from Module 10
# For this demo, we'll use the data_manager directly

# Import dataset manager
try:
    from examples.data_manager import DatasetManager
except ImportError:
    sys.path.append(os.path.join(project_root, 'examples'))
    from data_manager import DatasetManager

def flatten(x):
    """Flatten spatial features for dense layers - YOUR implementation!"""
    batch_size = x.data.shape[0]
    return Tensor(x.data.reshape(batch_size, -1))

class CIFARCNN:
    """
    Convolutional Neural Network for CIFAR-10 using YOUR TinyTorch!
    
    This architecture demonstrates how spatial feature extraction enables
    recognition of complex patterns in natural images.
    """
    
    def __init__(self):
        print("üß† Building CIFAR-10 CNN with YOUR TinyTorch modules...")
        
        # Convolutional feature extractors - YOUR spatial modules!
        self.conv1 = Conv2D(in_channels=3, out_channels=32, kernel_size=3)   # Module 09!
        self.conv2 = Conv2D(in_channels=32, out_channels=64, kernel_size=3)  # Module 09!
        self.pool = MaxPool2D(pool_size=2)  # Module 09: YOUR pooling!
        
        # Activation functions
        self.relu = ReLU()  # Module 03: YOUR activation!
        
        # Dense classification head
        # After conv1(32‚Üí30)‚Üípool(15)‚Üíconv2(13)‚Üípool(6): 64*6*6 = 2304 features
        self.fc1 = Linear(64 * 6 * 6, 256)  # Module 04: YOUR Linear!
        self.fc2 = Linear(256, 10)          # Module 04: YOUR Linear!
        
        # Calculate total parameters
        conv1_params = 3 * 3 * 3 * 32 + 32     # 3√ó3 kernels, 3‚Üí32 channels
        conv2_params = 3 * 3 * 32 * 64 + 64    # 3√ó3 kernels, 32‚Üí64 channels
        fc1_params = 64 * 6 * 6 * 256 + 256    # Flattened‚Üí256
        fc2_params = 256 * 10 + 10             # 256‚Üí10 classes
        self.total_params = conv1_params + conv2_params + fc1_params + fc2_params
        
        print(f"   Conv1: 3‚Üí32 channels (YOUR Conv2D extracts edges)")
        print(f"   Conv2: 32‚Üí64 channels (YOUR Conv2D builds shapes)")
        print(f"   Dense: 2304‚Üí256‚Üí10 (YOUR Linear classification)")
        print(f"   Total parameters: {self.total_params:,}")
        
    def forward(self, x):
        """Forward pass through YOUR CNN architecture."""
        # First conv block: Extract low-level features (edges, colors)
        x = self.conv1(x)           # Module 09: YOUR Conv2D!
        x = self.relu(x)            # Module 03: YOUR ReLU!
        x = self.pool(x)            # Module 09: YOUR MaxPool2D!
        
        # Second conv block: Build higher-level features (shapes, patterns)
        x = self.conv2(x)           # Module 09: YOUR Conv2D!
        x = self.relu(x)            # Module 03: YOUR ReLU!
        x = self.pool(x)            # Module 09: YOUR MaxPool2D!
        
        # Flatten and classify
        x = flatten(x)              # Module 09: YOUR spatial‚Üídense bridge!
        x = self.fc1(x)             # Module 04: YOUR Linear!
        x = self.relu(x)            # Module 03: YOUR ReLU!
        x = self.fc2(x)             # Module 04: YOUR classification!
        
        return x
    
    def parameters(self):
        """Get all trainable parameters from YOUR layers."""
        return [
            self.conv1.weight, self.conv1.bias,
            self.conv2.weight, self.conv2.bias,
            self.fc1.weight, self.fc1.bias,
            self.fc2.weight, self.fc2.bias
        ]

def visualize_cifar_cnn():
    """Show how CNNs process natural images."""
    print("\n" + "="*70)
    print("üñºÔ∏è  VISUALIZING CNN FEATURE EXTRACTION:")
    print("="*70)
    
    print("""
    How YOUR CNN Sees Images:           Feature Maps at Each Layer:
    
    Original Image (32√ó32√ó3):           After Conv1 (30√ó30√ó32):
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îå‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îê
    ‚îÇ [Cat in grass] ‚îÇ                 ‚îÇEdge detectors...‚îÇ 32 filters
    ‚îÇ Complex scene  ‚îÇ ‚Üí Conv+ReLU ‚Üí   ‚îÇTexture maps... ‚îÇ detect
    ‚îÇ Many patterns  ‚îÇ                 ‚îÇColor gradients. ‚îÇ features
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚îò
    
    After Pool1 (15√ó15√ó32):            After Conv2 (13√ó13√ó64):
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îå‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚î¨‚îÄ‚îê
    ‚îÇReduced  ‚îÇ                        ‚îÇCat ears...     ‚îÇ 64 filters
    ‚îÇspatial  ‚îÇ ‚Üí Conv+ReLU ‚Üí          ‚îÇCat eyes...     ‚îÇ combine
    ‚îÇdimension‚îÇ                        ‚îÇGrass texture...‚îÇ features
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îî‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚îò
    
    After Pool2 + Flatten:             Classification:
    [6√ó6√ó64 = 2304 features] ‚Üí Dense ‚Üí [plane|car|bird|CAT|...]
                                              Highest probability
    
    Key CNN Advantages YOUR Implementation Provides:
    ‚úì SPATIAL HIERARCHY: Low ‚Üí High level features
    ‚úì PARAMETER SHARING: 3√ó3 kernel used everywhere
    ‚úì TRANSLATION INVARIANCE: Detects patterns anywhere
    ‚úì AUTOMATIC FEATURE LEARNING: No manual engineering!
    """)
    print("="*70)

def train_cifar_cnn(model, train_data, train_labels, 
                    epochs=3, batch_size=32, learning_rate=0.001):
    """Train CNN using YOUR complete training system!"""
    print("\nüöÄ Training CIFAR-10 CNN with YOUR TinyTorch!")
    print(f"   Dataset: {len(train_data)} color images")
    print(f"   Batch size: {batch_size}")
    print(f"   YOUR Adam optimizer (Module 07)")
    
    # YOUR optimizer and loss
    optimizer = Adam(model.parameters(), learning_rate=learning_rate)
    loss_fn = CrossEntropyLoss()
    
    # Training loop
    num_batches = min(100, len(train_data) // batch_size)  # Demo mode
    
    for epoch in range(epochs):
        print(f"\n   Epoch {epoch+1}/{epochs}:")
        epoch_loss = 0
        correct = 0
        total = 0
        
        for batch_idx in range(num_batches):
            # Get batch
            start_idx = batch_idx * batch_size
            end_idx = start_idx + batch_size
            batch_X = train_data[start_idx:end_idx]
            batch_y = train_labels[start_idx:end_idx]
            
            # YOUR Tensors
            inputs = Tensor(batch_X)    # Module 02!
            targets = Tensor(batch_y)   # Module 02!
            
            # Forward pass with YOUR CNN
            outputs = model.forward(inputs)  # YOUR spatial features!
            loss = loss_fn(outputs, targets)  # Module 05!
            
            # Backward pass with YOUR autograd
            optimizer.zero_grad()  # Module 07!
            loss.backward()        # Module 06: YOUR autodiff!
            optimizer.step()       # Module 07!
            
            # Track accuracy
            predictions = np.argmax(outputs.data, axis=1)
            correct += np.sum(predictions == batch_y)
            total += len(batch_y)
            
            # Extract loss
            if hasattr(loss, 'item'):
                loss_value = loss.item()
            else:
                loss_value = float(loss.data) if not isinstance(loss.data, np.ndarray) else float(loss.data.flat[0])
            
            epoch_loss += loss_value
            
            # Progress
            if (batch_idx + 1) % 20 == 0:
                acc = 100 * correct / total
                print(f"   Batch {batch_idx+1}/{num_batches}: "
                      f"Loss = {loss_value:.4f}, Accuracy = {acc:.1f}%")
        
        # Epoch summary
        epoch_acc = 100 * correct / total
        avg_loss = epoch_loss / num_batches
        print(f"   ‚Üí Epoch Complete: Loss = {avg_loss:.4f}, "
              f"Accuracy = {epoch_acc:.1f}% (YOUR CNN learning!)")
    
    return model

def test_cifar_cnn(model, test_data, test_labels, class_names):
    """Test YOUR CNN on CIFAR-10 test set."""
    print("\nüß™ Testing YOUR CNN on Natural Images...")
    
    batch_size = 100
    correct = 0
    total = 0
    class_correct = np.zeros(10)
    class_total = np.zeros(10)
    
    # Test in batches
    num_test_batches = min(20, len(test_data) // batch_size)  # Demo
    
    for i in range(num_test_batches):
        batch_X = test_data[i*batch_size:(i+1)*batch_size]
        batch_y = test_labels[i*batch_size:(i+1)*batch_size]
        
        inputs = Tensor(batch_X)
        outputs = model.forward(inputs)
        
        predictions = np.argmax(outputs.data, axis=1)
        correct += np.sum(predictions == batch_y)
        total += len(batch_y)
        
        # Per-class accuracy
        for j in range(len(batch_y)):
            label = batch_y[j]
            class_total[label] += 1
            if predictions[j] == label:
                class_correct[label] += 1
    
    # Results
    accuracy = 100 * correct / total
    print(f"\n   üìä Overall Test Accuracy: {accuracy:.2f}%")
    
    # Per-class performance
    print("\n   Per-Class Performance (YOUR CNN's understanding):")
    print("   " + "‚îÄ"*50)
    print("   ‚îÇ Class      ‚îÇ Accuracy ‚îÇ Visual               ‚îÇ")
    print("   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
    
    for i, class_name in enumerate(class_names):
        if class_total[i] > 0:
            class_acc = 100 * class_correct[i] / class_total[i]
            bar_length = int(class_acc / 5)
            bar = "‚ñà" * bar_length + "‚ñë" * (20 - bar_length)
            print(f"   ‚îÇ {class_name:10} ‚îÇ  {class_acc:5.1f}%  ‚îÇ {bar} ‚îÇ")
    
    print("   " + "‚îÄ"*50)
    
    if accuracy >= 65:
        print("\n   üéâ EXCELLENT! YOUR CNN mastered natural image recognition!")
    elif accuracy >= 50:
        print("\n   ‚úÖ Good progress! YOUR CNN is learning visual features!")
    else:
        print("\n   üîÑ YOUR CNN is still learning... (normal for demo mode)")
    
    return accuracy

def analyze_cnn_systems(model):
    """Analyze YOUR CNN from an ML systems perspective."""
    print("\nüî¨ SYSTEMS ANALYSIS of YOUR CNN Implementation:")
    
    print(f"\n   Model Architecture:")
    print(f"   ‚Ä¢ Convolutional layers: 2 (3‚Üí32‚Üí64 channels)")
    print(f"   ‚Ä¢ Pooling layers: 2 (2√ó2 max pooling)")
    print(f"   ‚Ä¢ Dense layers: 2 (2304‚Üí256‚Üí10)")
    print(f"   ‚Ä¢ Total parameters: {model.total_params:,}")
    
    print(f"\n   Computational Complexity:")
    print(f"   ‚Ä¢ Conv1: 32√ó30√ó30√ó(3√ó3√ó3) = 777,600 ops")
    print(f"   ‚Ä¢ Conv2: 64√ó13√ó13√ó(3√ó3√ó32) = 3,093,504 ops")
    print(f"   ‚Ä¢ Dense: 2,304√ó256 + 256√ó10 = 592,384 ops")
    print(f"   ‚Ä¢ Total: ~4.5M ops per image")
    
    print(f"\n   Memory Requirements:")
    print(f"   ‚Ä¢ Parameters: {model.total_params * 4 / 1024:.1f} KB")
    print(f"   ‚Ä¢ Activations (peak): ~500 KB per image")
    print(f"   ‚Ä¢ YOUR implementation: Pure Python + NumPy")
    
    print(f"\n   üèõÔ∏è CNN Evolution:")
    print(f"   ‚Ä¢ 1989: LeCun's CNN for handwritten digits")
    print(f"   ‚Ä¢ 2012: AlexNet revolutionizes ImageNet")
    print(f"   ‚Ä¢ 2015: ResNet enables 100+ layer networks")
    print(f"   ‚Ä¢ YOUR CNN: Core principles that power them all!")
    
    print(f"\n   üí° Why CNNs Dominate Vision:")
    print(f"   ‚Ä¢ Spatial hierarchy matches visual cortex")
    print(f"   ‚Ä¢ Parameter sharing: 3√ó3 kernel vs 32√ó32 dense")
    print(f"   ‚Ä¢ Translation invariance from weight sharing")
    print(f"   ‚Ä¢ YOUR implementation demonstrates all of these!")

def main():
    """Demonstrate CIFAR-10 CNN using YOUR TinyTorch!"""
    
    parser = argparse.ArgumentParser(description='CIFAR-10 CNN')
    parser.add_argument('--test-only', action='store_true',
                       help='Test architecture only')
    parser.add_argument('--epochs', type=int, default=3,
                       help='Training epochs (demo mode)')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='Batch size')
    parser.add_argument('--visualize', action='store_true', default=True,
                       help='Show CNN visualization')
    parser.add_argument('--quick-test', action='store_true',
                       help='Use small subset for testing')
    args = parser.parse_args()
    
    print("üéØ CIFAR-10 CNN - Natural Image Recognition with YOUR Spatial Modules!")
    print("   Historical significance: CNNs revolutionized computer vision")
    print("   YOUR achievement: Spatial feature extraction on real photos")
    print("   Components used: YOUR Conv2D + MaxPool2D + complete system")
    
    # Visualization
    if args.visualize:
        visualize_cifar_cnn()
    
    # Class names
    class_names = ['plane', 'car', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']
    
    # Step 1: Load CIFAR-10
    print("\nüì• Loading CIFAR-10 dataset...")
    data_manager = DatasetManager()
    
    try:
        (train_data, train_labels), (test_data, test_labels) = data_manager.get_cifar10()
        print(f"‚úÖ Loaded {len(train_data)} training, {len(test_data)} test images")
        
        if args.quick_test:
            train_data = train_data[:1000]
            train_labels = train_labels[:1000]
            test_data = test_data[:500]
            test_labels = test_labels[:500]
            print("   (Using subset for quick testing)")
            
    except Exception as e:
        print(f"‚ö†Ô∏è  CIFAR-10 download failed: {e}")
        print("   Using synthetic data for architecture testing...")
        train_data = np.random.randn(100, 3, 32, 32).astype(np.float32)
        train_labels = np.random.randint(0, 10, 100).astype(np.int64)
        test_data = np.random.randn(20, 3, 32, 32).astype(np.float32)
        test_labels = np.random.randint(0, 10, 20).astype(np.int64)
    
    # Step 2: Build CNN
    model = CIFARCNN()
    
    if args.test_only:
        print("\nüß™ ARCHITECTURE TEST MODE")
        test_input = Tensor(train_data[:5])
        test_output = model.forward(test_input)
        print(f"‚úÖ Forward pass successful! Shape: {test_output.data.shape}")
        print("‚úÖ YOUR CNN architecture works!")
        return
    
    # Step 3: Train
    start_time = time.time()
    model = train_cifar_cnn(model, train_data, train_labels,
                           epochs=args.epochs, batch_size=args.batch_size)
    train_time = time.time() - start_time
    
    # Step 4: Test
    accuracy = test_cifar_cnn(model, test_data, test_labels, class_names)
    
    # Step 5: Analysis
    analyze_cnn_systems(model)
    
    print(f"\n‚è±Ô∏è  Training time: {train_time:.1f} seconds")
    print(f"   Images/sec: {len(train_data) * args.epochs / train_time:.0f}")
    
    print("\n‚úÖ SUCCESS! CIFAR-10 CNN Milestone Complete!")
    print("\nüéì What YOU Accomplished:")
    print("   ‚Ä¢ YOUR Conv2D extracts spatial features from natural images")
    print("   ‚Ä¢ YOUR MaxPool2D reduces dimensions while preserving information")
    print("   ‚Ä¢ YOUR CNN achieves real accuracy on complex photos")
    print("   ‚Ä¢ YOUR implementation demonstrates core computer vision principles!")
    
    print("\nüöÄ Next Steps:")
    print("   ‚Ä¢ Continue to TinyGPT after Module 14 (Transformers)")
    print("   ‚Ä¢ YOUR spatial understanding scales to segmentation, detection, etc.")
    print(f"   ‚Ä¢ With {accuracy:.1f}% accuracy, YOUR computer vision works!")

if __name__ == "__main__":
    main()