================================================================================
PEDAGOGICAL FIGURE PROPOSALS - VISUAL SUMMARY
================================================================================
Generated: 2025-11-17
Paper: /Users/VJ/GitHub/TinyTorch/paper/paper.tex

This document provides ASCII mockups of the proposed figures to help you
visualize them before compiling the LaTeX code.

================================================================================
FIGURE A: PROGRESSIVE DISCLOSURE TIMELINE (HIGHEST PRIORITY)
================================================================================
Location: Section 3.1, after Listing 2 (line ~660)
Pedagogical Value: Visualizes paper's most novel contribution

ASCII Mockup:
------------------------------------------------------------------------------
                        Progressive Disclosure of Tensor Capabilities

    Modules:  M01        M03        M05        M09        M13        M20
              |          |          |          |          |          |
Timeline: ----o----------o----------o----------o----------o----------o-----→

Feature Layers (stacked):

Core      =====[.data]====[.shape]================================== (Active)
(always)

Gradient  - - -[.requires_grad]- - -    =================== (Dormant→Active)
                                 ↑
                            ACTIVATION!
                                 ↓
          - - -[.grad]- - - - - -    ======================== (Dormant→Active)

          - - -[.backward()]- - -    ======================== (Dormant→Active)


Legend:  ====  Active (orange)     - - -  Dormant (gray dashed)

Annotations:
  Modules 01-04:                          Modules 05-20:
  Features visible but dormant            Autograd fully active
  .backward() is no-op                    Gradients flow automatically

------------------------------------------------------------------------------
Why This Figure Matters:
- Currently, progressive disclosure is explained only through code listings
- Visual instantly shows which features are dormant vs active when
- Makes cognitive load management visible (features phase in progressively)
- Readers can grasp the pattern at a glance instead of reading code carefully

================================================================================
FIGURE B: MEMORY HIERARCHY BREAKDOWN (HIGH PRIORITY)
================================================================================
Location: Section 4.1, after Table 1 (line ~744)
Pedagogical Value: Clarifies that activations dominate, not just optimizer state

ASCII Mockup:
------------------------------------------------------------------------------
                        Memory Usage: SGD vs Adam Optimizers

    SGD Optimizer                           Adam Optimizer

    |                                       |
32× |  ╔════════════════════╗         34× |  ╔════════════════════╗
    |  ║                    ║              |  ║                    ║
    |  ║                    ║              |  ║                    ║
    |  ║   ACTIVATIONS      ║              |  ║   ACTIVATIONS      ║
    |  ║   (10-100×)        ║              |  ║   (10-100×)        ║
 16×|  ║                    ║          16×|  ║                    ║
    |  ║  ← DOMINATES!      ║              |  ║  ← STILL           ║
    |  ║                    ║              |  ║    DOMINATES!      ║
    |  ║                    ║              |  ║                    ║
    |  ╠════════════════════╣              |  ╠════════════════════╣
  2×|  ║ GRADIENTS (1×)     ║           4×|  ║ VARIANCE (1×)      ║─┐
    |  ╠════════════════════╣              |  ╠════════════════════╣ │
  1×|  ║ PARAMETERS (1×)    ║           3×|  ║ MOMENTUM (1×)      ║ ├─ +2× optimizer
    |  ╚════════════════════╝              |  ╠════════════════════╣ │  states
  0×|                                   2×|  ║ GRADIENTS (1×)     ║─┘
                                           |  ╠════════════════════╣
                                        1×|  ║ PARAMETERS (1×)    ║
                                           |  ╚════════════════════╝
                                        0×|

    Total: 32× params                      Total: 34× params

┌─────────────────────────────────────────────────────────────────────┐
│ KEY INSIGHT: Adam adds 2× parameter memory (3× total vs 1× for     │
│ SGD), but activations still dominate overall memory usage by       │
│ 10-100×. Optimizer choice affects parameter overhead, not the      │
│ primary memory bottleneck.                                          │
└─────────────────────────────────────────────────────────────────────┘

------------------------------------------------------------------------------
Why This Figure Matters:
- Paper mentions "Adam uses 3× parameter memory" but students often miss
  that this is small compared to activation memory
- Visual makes the proportions concrete and memorable
- Shows systems thinking: calculate each component, understand dominance
- Prevents common misconception that optimizer is the main memory concern

================================================================================
FIGURE C: BUILD→USE→REFLECT CYCLE (HIGH PRIORITY)
================================================================================
Location: Section 2.3, Module Structure (line ~492)
Pedagogical Value: Core pedagogical pattern - deserves visual clarity

ASCII Mockup:
------------------------------------------------------------------------------
                    Pedagogical Cycle: Every Module

                           ╔═══════════════╗
                           ║     BUILD     ║
                           ║ Implementation║
                           ╚═══════════════╝
                                  │
                                  │ Test
                                  ↓
      ╔═══════════════╗                      ╔═══════════════╗
      ║    REFLECT    ║  ← ─ ─ ─ ─ ─ ─ ─ ─   ║      USE      ║
      ║   Analysis    ║       Analyze         ║  Integration  ║
      ╚═══════════════╝                      ╚═══════════════╝
              │
              │ Iterate
              └──────────────────────────────────────┘

                    ⟲  Repeats for all 20 modules


Example: Module 05 (Autograd)
┌─────────────────────────┬──────────────────────────┬─────────────────────┐
│ BUILD                   │ USE                      │ REFLECT             │
├─────────────────────────┼──────────────────────────┼─────────────────────┤
│ • Implement backward()  │ • Unit test: Does        │ • Memory: Gradient  │
│ • Build comp. graph     │   .backward() work?      │   storage overhead? │
│ • Gradient accumulation │ • Integration: Gradients │ • Complexity: O(?)  │
│ • Scaffold: Connection  │   through M03 layers?    │   for backprop?     │
│   maps                  │ • NBGrader: Autograde    │ • Design: Why       │
│                         │ • Milestone: Train net   │   comp. graphs?     │
│                         │   end-to-end             │ • Transfer: PyTorch?│
└─────────────────────────┴──────────────────────────┴─────────────────────┘

------------------------------------------------------------------------------
Why This Figure Matters:
- The Build→Use→Reflect pattern structures ALL 20 modules but is currently
  only described in prose
- Visual makes the iterative cycle explicit
- Shows concrete examples at each phase (not just abstract phases)
- Reinforces cognitive apprenticeship (making expert patterns visible)

================================================================================
FIGURE D: HISTORICAL MILESTONE TIMELINE (MEDIUM PRIORITY)
================================================================================
Location: Section 4.3, Historical Validation (line ~773)
Pedagogical Value: Shows 70-year capability accumulation visually

ASCII Mockup:
------------------------------------------------------------------------------
            Historical Milestones: 70 Years of ML Progress

Timeline: ──o────────o────────o────────o────────o────────o──────→
        1957      1969      1986      1998      2017      2024


        ┌───────────┐         ┌───────────┐         ┌───────────┐
        │ M2: XOR   │         │ M4: CNN   │         │ M6: Prod  │
        │ Mods 01-07│         │ Mods 01-09│         │ All 20    │
        │ Multi-    │         │ 75%+      │         │ Olympics  │
        │ layer     │         │ CIFAR-10  │         │ Optimized │
        └─────┬─────┘         └─────┬─────┘         └─────┬─────┘
              │                     │                     │
   ┌──────────┴─────┐    ┌──────────┴─────┐    ┌──────────┴─────┐
   │ M1: Perceptron │    │ M3: MNIST MLP  │    │ M5: Transformer│
   │ Mods 01-04     │    │ Mods 01-08     │    │ Mods 01-13     │
   │ Linear sep.    │    │ 95%+ digits    │    │ Text gen.      │
   └────────────────┘    └────────────────┘    └────────────────┘

   ─ ─ ─ ─ ─ → ─ ─ ─ ─ ─ → ─ ─ ─ ─ ─ → ─ ─ ─ ─ ─ → ─ ─ ─ ─ ─ →
           Capability Accumulation (each builds on prior)

Color Coding:
  M1-M2: Foundation (Blue)    M3-M4: Architectures (Green)
  M5: Language (Purple)       M6: Optimization (Red)

------------------------------------------------------------------------------
Why This Figure Matters:
- 70-year progression is compelling but currently just a numbered list
- Visual timeline shows temporal progression and capability accumulation
- Arrows show dependencies (later milestones require earlier modules)
- Enhances the historical motivation narrative

================================================================================

IMPLEMENTATION STATUS
================================================================================

Files Created:
✓ /Users/VJ/GitHub/TinyTorch/paper/proposed_figures.tex
  - Full LaTeX document with all 4 figures as TikZ code
  - Includes captions and compilation instructions
  - Can be compiled standalone OR extracted for integration

✓ /Users/VJ/GitHub/TinyTorch/paper/FIGURE_PROPOSALS.md
  - Detailed proposal document
  - Pedagogical rationale for each figure
  - Integration instructions
  - Priority ranking and justification

✓ /Users/VJ/GitHub/TinyTorch/paper/FIGURE_SUMMARY.txt
  - This file - ASCII mockups for quick visualization

To Review Figures:
1. Compile standalone: cd paper && lualatex proposed_figures.tex
2. Review this ASCII summary for quick understanding
3. Read FIGURE_PROPOSALS.md for detailed rationale
4. Decide on integration approach (see below)

================================================================================

INTEGRATION OPTIONS
================================================================================

Option A: Extract Individual Figure Files
Create separate .tex files in figures/ subdirectory:
  - figures/fig_progressive_timeline.tex
  - figures/fig_memory_breakdown.tex
  - figures/fig_build_use_reflect.tex
  - figures/fig_milestone_progression.tex

Then in paper.tex, add:
  \input{figures/fig_progressive_timeline.tex}
  (at appropriate locations)

Option B: Direct Integration
Copy TikZ code from proposed_figures.tex directly into paper.tex
at the section locations specified in FIGURE_PROPOSALS.md

Option C: Iterative Review
1. Compile proposed_figures.tex standalone
2. Review visual output
3. Request modifications
4. Iterate on design
5. Then integrate into paper

================================================================================

PRIORITY RECOMMENDATION
================================================================================

If adding only ONE figure:
  → Progressive Disclosure Timeline (Figure A)
    Most novel contribution, currently lacks visual support

If adding TWO figures:
  → Progressive Disclosure Timeline (Figure A)
  → Memory Hierarchy Breakdown (Figure B)
    Novel contribution + systems-first clarification

If adding THREE figures:
  → Add Build→Use→Reflect Cycle (Figure C)
    Complete visual coverage of pedagogical patterns

If adding ALL FOUR:
  → Include Milestone Timeline (Figure D)
    Complete the historical narrative visually

================================================================================

NEXT STEPS
================================================================================

1. Review this ASCII summary to understand proposed figures
2. Read FIGURE_PROPOSALS.md for detailed pedagogical rationale
3. Compile proposed_figures.tex to see actual visual output
4. Decide which figures to include (priority recommendations above)
5. Choose integration approach (Options A, B, or C above)
6. Provide feedback on any modifications needed

All TikZ code is production-ready and matches the paper's existing color
scheme and design language. Figures are intentionally pedagogically focused
(not decorative) and designed to clarify concepts currently explained only
in prose.

================================================================================
END OF SUMMARY
================================================================================
