{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c079683",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Module 5: CNN - Convolutional Neural Networks\n",
    "\n",
    "Welcome to the CNN module! Here you'll implement the core building block of modern computer vision: the convolutional layer.\n",
    "\n",
    "## Learning Goals\n",
    "- Understand the convolution operation and its importance in computer vision\n",
    "- Implement Conv2D with explicit for-loops to understand the sliding window mechanism\n",
    "- Build convolutional layers that can detect spatial patterns in images\n",
    "- Compose Conv2D with other layers to build complete convolutional networks\n",
    "- See how convolution enables parameter sharing and translation invariance\n",
    "\n",
    "## Build â†’ Use â†’ Understand\n",
    "1. **Build**: Conv2D layer using sliding window convolution from scratch\n",
    "2. **Use**: Transform images and see feature maps emerge\n",
    "3. **Understand**: How CNNs learn hierarchical spatial patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76af25",
   "metadata": {
    "lines_to_next_cell": 1,
    "nbgrader": {
     "grade": false,
     "grade_id": "cnn-imports",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp core.cnn\n",
    "\n",
    "#| export\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import from the main package - try package first, then local modules\n",
    "try:\n",
    "    from tinytorch.core.tensor import Tensor\n",
    "    from tinytorch.core.layers import Dense\n",
    "    from tinytorch.core.activations import ReLU\n",
    "except ImportError:\n",
    "    # For development, import from local modules\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..', '01_tensor'))\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..', '02_activations'))\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..', '03_layers'))\n",
    "    from tensor_dev import Tensor\n",
    "    from activations_dev import ReLU\n",
    "    from layers_dev import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a77ffd",
   "metadata": {
    "lines_to_next_cell": 1,
    "nbgrader": {
     "grade": false,
     "grade_id": "cnn-setup",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "def _should_show_plots():\n",
    "    \"\"\"Check if we should show plots (disable during testing)\"\"\"\n",
    "    # Check multiple conditions that indicate we're in test mode\n",
    "    is_pytest = (\n",
    "        'pytest' in sys.modules or\n",
    "        'test' in sys.argv or\n",
    "        os.environ.get('PYTEST_CURRENT_TEST') is not None or\n",
    "        any('test' in arg for arg in sys.argv) or\n",
    "        any('pytest' in arg for arg in sys.argv)\n",
    "    )\n",
    "    \n",
    "    # Show plots in development mode (when not in test mode)\n",
    "    return not is_pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858230f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cnn-welcome",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ”¥ TinyTorch CNN Module\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Python version: {sys.version_info.major}.{sys.version_info.minor}\")\n",
    "print(\"Ready to build convolutional neural networks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de89fcd",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## ğŸ“¦ Where This Code Lives in the Final Package\n",
    "\n",
    "**Learning Side:** You work in `modules/source/05_cnn/cnn_dev.py`  \n",
    "**Building Side:** Code exports to `tinytorch.core.cnn`\n",
    "\n",
    "```python\n",
    "# Final package structure:\n",
    "from tinytorch.core.cnn import Conv2D, conv2d_naive, flatten  # CNN operations!\n",
    "from tinytorch.core.layers import Dense  # Fully connected layers\n",
    "from tinytorch.core.activations import ReLU  # Nonlinearity\n",
    "from tinytorch.core.tensor import Tensor  # Foundation\n",
    "```\n",
    "\n",
    "**Why this matters:**\n",
    "- **Learning:** Focused modules for deep understanding of convolution\n",
    "- **Production:** Proper organization like PyTorch's `torch.nn.Conv2d`\n",
    "- **Consistency:** All CNN operations live together in `core.cnn`\n",
    "- **Integration:** Works seamlessly with other TinyTorch components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588174f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## ğŸ§  The Mathematical Foundation of Convolution\n",
    "\n",
    "### The Convolution Operation\n",
    "Convolution is a mathematical operation that combines two functions to produce a third function:\n",
    "\n",
    "```\n",
    "(f * g)(t) = âˆ« f(Ï„)g(t - Ï„)dÏ„\n",
    "```\n",
    "\n",
    "In discrete 2D computer vision, this becomes:\n",
    "```\n",
    "(I * K)[i,j] = Î£Î£ I[i+m, j+n] Ã— K[m,n]\n",
    "```\n",
    "\n",
    "### Why Convolution is Perfect for Images\n",
    "- **Local connectivity**: Each output depends only on a small region of input\n",
    "- **Weight sharing**: Same filter applied everywhere (translation invariance)\n",
    "- **Spatial hierarchy**: Multiple layers build increasingly complex features\n",
    "- **Parameter efficiency**: Much fewer parameters than fully connected layers\n",
    "\n",
    "### The Three Core Principles\n",
    "1. **Sparse connectivity**: Each neuron connects to only a small region\n",
    "2. **Parameter sharing**: Same weights used across all spatial locations\n",
    "3. **Equivariant representation**: If input shifts, output shifts correspondingly\n",
    "\n",
    "### Connection to Real ML Systems\n",
    "Every vision framework uses convolution:\n",
    "- **PyTorch**: `torch.nn.Conv2d` with optimized CUDA kernels\n",
    "- **TensorFlow**: `tf.keras.layers.Conv2D` with cuDNN acceleration\n",
    "- **JAX**: `jax.lax.conv_general_dilated` with XLA compilation\n",
    "- **TinyTorch**: `tinytorch.core.cnn.Conv2D` (what we're building!)\n",
    "\n",
    "### Performance Considerations\n",
    "- **Memory layout**: Efficient data access patterns\n",
    "- **Vectorization**: SIMD operations for parallel computation\n",
    "- **Cache efficiency**: Spatial locality in memory access\n",
    "- **Optimization**: im2col, FFT-based convolution, Winograd algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68a4a4e",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Step 1: Understanding Convolution\n",
    "\n",
    "### What is Convolution?\n",
    "A **convolutional layer** applies a small filter (kernel) across the input, producing a feature map. This operation captures local patterns and is the foundation of modern vision models.\n",
    "\n",
    "### Why Convolution Matters in Computer Vision\n",
    "- **Local connectivity**: Each output value depends only on a small region of the input\n",
    "- **Weight sharing**: The same filter is applied everywhere (translation invariance)\n",
    "- **Spatial hierarchy**: Multiple layers build increasingly complex features\n",
    "- **Parameter efficiency**: Much fewer parameters than fully connected layers\n",
    "\n",
    "### The Fundamental Insight\n",
    "**Convolution is pattern matching!** The kernel learns to detect specific patterns:\n",
    "- **Edge detectors**: Find boundaries between objects\n",
    "- **Texture detectors**: Recognize surface patterns\n",
    "- **Shape detectors**: Identify geometric forms\n",
    "- **Feature detectors**: Combine simple patterns into complex features\n",
    "\n",
    "### Real-World Examples\n",
    "- **Image processing**: Detect edges, blur, sharpen\n",
    "- **Computer vision**: Recognize objects, faces, text\n",
    "- **Medical imaging**: Detect tumors, analyze scans\n",
    "- **Autonomous driving**: Identify traffic signs, pedestrians\n",
    "\n",
    "### Visual Intuition\n",
    "```\n",
    "Input Image:     Kernel:        Output Feature Map:\n",
    "[1, 2, 3]       [1,  0]       [1*1+2*0+4*0+5*(-1), 2*1+3*0+5*0+6*(-1)]\n",
    "[4, 5, 6]       [0, -1]       [4*1+5*0+7*0+8*(-1), 5*1+6*0+8*0+9*(-1)]\n",
    "[7, 8, 9]\n",
    "```\n",
    "\n",
    "The kernel slides across the input, computing dot products at each position.\n",
    "\n",
    "Let's implement this step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fd05a",
   "metadata": {
    "lines_to_next_cell": 1,
    "nbgrader": {
     "grade": false,
     "grade_id": "conv2d-naive",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def conv2d_naive(input: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Naive 2D convolution (single channel, no stride, no padding).\n",
    "    \n",
    "    Args:\n",
    "        input: 2D input array (H, W)\n",
    "        kernel: 2D filter (kH, kW)\n",
    "    Returns:\n",
    "        2D output array (H-kH+1, W-kW+1)\n",
    "        \n",
    "    TODO: Implement the sliding window convolution using for-loops.\n",
    "    \n",
    "    APPROACH:\n",
    "    1. Get input dimensions: H, W = input.shape\n",
    "    2. Get kernel dimensions: kH, kW = kernel.shape\n",
    "    3. Calculate output dimensions: out_H = H - kH + 1, out_W = W - kW + 1\n",
    "    4. Create output array: np.zeros((out_H, out_W))\n",
    "    5. Use nested loops to slide the kernel:\n",
    "       - i loop: output rows (0 to out_H-1)\n",
    "       - j loop: output columns (0 to out_W-1)\n",
    "       - di loop: kernel rows (0 to kH-1)\n",
    "       - dj loop: kernel columns (0 to kW-1)\n",
    "    6. For each (i,j), compute: output[i,j] += input[i+di, j+dj] * kernel[di, dj]\n",
    "    \n",
    "    EXAMPLE:\n",
    "    Input: [[1, 2, 3],     Kernel: [[1, 0],\n",
    "            [4, 5, 6],               [0, -1]]\n",
    "            [7, 8, 9]]\n",
    "    \n",
    "    Output[0,0] = 1*1 + 2*0 + 4*0 + 5*(-1) = 1 - 5 = -4\n",
    "    Output[0,1] = 2*1 + 3*0 + 5*0 + 6*(-1) = 2 - 6 = -4\n",
    "    Output[1,0] = 4*1 + 5*0 + 7*0 + 8*(-1) = 4 - 8 = -4\n",
    "    Output[1,1] = 5*1 + 6*0 + 8*0 + 9*(-1) = 5 - 9 = -4\n",
    "    \n",
    "    HINTS:\n",
    "    - Start with output = np.zeros((out_H, out_W))\n",
    "    - Use four nested loops: for i in range(out_H): for j in range(out_W): for di in range(kH): for dj in range(kW):\n",
    "    - Accumulate the sum: output[i,j] += input[i+di, j+dj] * kernel[di, dj]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    # Get input and kernel dimensions\n",
    "    H, W = input.shape\n",
    "    kH, kW = kernel.shape\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    out_H, out_W = H - kH + 1, W - kW + 1\n",
    "    \n",
    "    # Initialize output array\n",
    "    output = np.zeros((out_H, out_W), dtype=input.dtype)\n",
    "    \n",
    "    # Sliding window convolution with four nested loops\n",
    "    for i in range(out_H):\n",
    "        for j in range(out_W):\n",
    "            for di in range(kH):\n",
    "                for dj in range(kW):\n",
    "                    output[i, j] += input[i + di, j + dj] * kernel[di, dj]\n",
    "    \n",
    "    return output\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717be836",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### ğŸ§ª Quick Test: Convolution Operation\n",
    "\n",
    "Let's test your convolution implementation right away! This is the core operation that powers computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c93d02",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test-conv2d-naive-immediate",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test conv2d_naive function immediately after implementation\n",
    "print(\"ğŸ”¬ Testing convolution operation...\")\n",
    "\n",
    "# Test simple 3x3 input with 2x2 kernel\n",
    "try:\n",
    "    input_array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.float32)\n",
    "    kernel_array = np.array([[1, 0], [0, 1]], dtype=np.float32)  # Identity-like kernel\n",
    "    \n",
    "    result = conv2d_naive(input_array, kernel_array)\n",
    "    expected = np.array([[6, 8], [12, 14]], dtype=np.float32)  # 1+5, 2+6, 4+8, 5+9\n",
    "    \n",
    "    print(f\"Input:\\n{input_array}\")\n",
    "    print(f\"Kernel:\\n{kernel_array}\")\n",
    "    print(f\"Result:\\n{result}\")\n",
    "    print(f\"Expected:\\n{expected}\")\n",
    "    \n",
    "    assert np.allclose(result, expected), f\"Convolution failed: expected {expected}, got {result}\"\n",
    "    print(\"âœ… Simple convolution test passed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Simple convolution test failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test edge detection kernel\n",
    "try:\n",
    "    input_array = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]], dtype=np.float32)\n",
    "    edge_kernel = np.array([[-1, -1], [-1, 3]], dtype=np.float32)  # Edge detection\n",
    "    \n",
    "    result = conv2d_naive(input_array, edge_kernel)\n",
    "    expected = np.array([[0, 0], [0, 0]], dtype=np.float32)  # Uniform region = no edges\n",
    "    \n",
    "    assert np.allclose(result, expected), f\"Edge detection failed: expected {expected}, got {result}\"\n",
    "    print(\"âœ… Edge detection test passed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Edge detection test failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test output shape\n",
    "try:\n",
    "    input_5x5 = np.random.randn(5, 5).astype(np.float32)\n",
    "    kernel_3x3 = np.random.randn(3, 3).astype(np.float32)\n",
    "    \n",
    "    result = conv2d_naive(input_5x5, kernel_3x3)\n",
    "    expected_shape = (3, 3)  # 5-3+1 = 3\n",
    "    \n",
    "    assert result.shape == expected_shape, f\"Output shape wrong: expected {expected_shape}, got {result.shape}\"\n",
    "    print(\"âœ… Output shape test passed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Output shape test failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Show the convolution process\n",
    "print(\"ğŸ¯ Convolution behavior:\")\n",
    "print(\"   Slides kernel across input\")\n",
    "print(\"   Computes dot product at each position\")\n",
    "print(\"   Output size = Input size - Kernel size + 1\")\n",
    "print(\"ğŸ“ˆ Progress: Convolution operation âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc62ad",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Step 2: Building the Conv2D Layer\n",
    "\n",
    "### What is a Conv2D Layer?\n",
    "A **Conv2D layer** is a learnable convolutional layer that:\n",
    "- Has learnable kernel weights (initialized randomly)\n",
    "- Applies convolution to input tensors\n",
    "- Integrates with the rest of the neural network\n",
    "\n",
    "### Why Conv2D Layers Matter\n",
    "- **Feature learning**: Kernels learn to detect useful patterns\n",
    "- **Composability**: Can be stacked with other layers\n",
    "- **Efficiency**: Shared weights reduce parameters dramatically\n",
    "- **Translation invariance**: Same patterns detected anywhere in the image\n",
    "\n",
    "### Real-World Applications\n",
    "- **Image classification**: Recognize objects in photos\n",
    "- **Object detection**: Find and locate objects\n",
    "- **Medical imaging**: Detect anomalies in scans\n",
    "- **Autonomous driving**: Identify road features\n",
    "\n",
    "### Design Decisions\n",
    "- **Kernel size**: Typically 3Ã—3 or 5Ã—5 for balance of locality and capacity\n",
    "- **Initialization**: Small random values to break symmetry\n",
    "- **Integration**: Works with Tensor class and other layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cfe98a",
   "metadata": {
    "lines_to_next_cell": 1,
    "nbgrader": {
     "grade": false,
     "grade_id": "conv2d-class",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class Conv2D:\n",
    "    \"\"\"\n",
    "    2D Convolutional Layer (single channel, single filter, no stride/pad).\n",
    "    \n",
    "    A learnable convolutional layer that applies a kernel to detect spatial patterns.\n",
    "    Perfect for building the foundation of convolutional neural networks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_size: Tuple[int, int]):\n",
    "        \"\"\"\n",
    "        Initialize Conv2D layer with random kernel.\n",
    "        \n",
    "        Args:\n",
    "            kernel_size: (kH, kW) - size of the convolution kernel\n",
    "            \n",
    "        TODO: Initialize a random kernel with small values.\n",
    "        \n",
    "        APPROACH:\n",
    "        1. Store kernel_size as instance variable\n",
    "        2. Initialize random kernel with small values\n",
    "        3. Use proper initialization for stable training\n",
    "        \n",
    "        EXAMPLE:\n",
    "        Conv2D((2, 2)) creates:\n",
    "        - kernel: shape (2, 2) with small random values\n",
    "        \n",
    "        HINTS:\n",
    "        - Store kernel_size as self.kernel_size\n",
    "        - Initialize kernel: np.random.randn(kH, kW) * 0.1 (small values)\n",
    "        - Convert to float32 for consistency\n",
    "        \"\"\"\n",
    "        ### BEGIN SOLUTION\n",
    "        # Store kernel size\n",
    "        self.kernel_size = kernel_size\n",
    "        kH, kW = kernel_size\n",
    "        \n",
    "        # Initialize random kernel with small values\n",
    "        self.kernel = np.random.randn(kH, kW).astype(np.float32) * 0.1\n",
    "        ### END SOLUTION\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass: apply convolution to input tensor.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor (2D for simplicity)\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor after convolution\n",
    "            \n",
    "        TODO: Implement forward pass using conv2d_naive function.\n",
    "        \n",
    "        APPROACH:\n",
    "        1. Extract numpy array from input tensor\n",
    "        2. Apply conv2d_naive with stored kernel\n",
    "        3. Return result wrapped in Tensor\n",
    "        \n",
    "        EXAMPLE:\n",
    "        x = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # shape (3, 3)\n",
    "        layer = Conv2D((2, 2))\n",
    "        y = layer(x)  # shape (2, 2)\n",
    "        \n",
    "        HINTS:\n",
    "        - Use x.data to get numpy array\n",
    "        - Use conv2d_naive(x.data, self.kernel)\n",
    "        - Return Tensor(result) to wrap the result\n",
    "        \"\"\"\n",
    "        ### BEGIN SOLUTION\n",
    "        # Apply convolution using naive implementation\n",
    "        result = conv2d_naive(x.data, self.kernel)\n",
    "        return Tensor(result)\n",
    "        ### END SOLUTION\n",
    "    \n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Make layer callable: layer(x) same as layer.forward(x)\"\"\"\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121076b0",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### ğŸ§ª Quick Test: Conv2D Layer\n",
    "\n",
    "Let's test your Conv2D layer implementation! This is a learnable convolutional layer that can be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c0d8f",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test-conv2d-layer-immediate",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Conv2D layer immediately after implementation\n",
    "print(\"ğŸ”¬ Testing Conv2D layer...\")\n",
    "\n",
    "# Create a Conv2D layer\n",
    "try:\n",
    "    layer = Conv2D(kernel_size=(2, 2))\n",
    "    print(f\"Conv2D layer created with kernel size: {layer.kernel_size}\")\n",
    "    print(f\"Kernel shape: {layer.kernel.shape}\")\n",
    "    \n",
    "    # Test that kernel is initialized properly\n",
    "    assert layer.kernel.shape == (2, 2), f\"Kernel shape should be (2, 2), got {layer.kernel.shape}\"\n",
    "    assert not np.allclose(layer.kernel, 0), \"Kernel should not be all zeros\"\n",
    "    print(\"âœ… Conv2D layer initialization successful\")\n",
    "    \n",
    "    # Test with sample input\n",
    "    x = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    \n",
    "    y = layer(x)\n",
    "    print(f\"Output shape: {y.shape}\")\n",
    "    print(f\"Output: {y}\")\n",
    "    \n",
    "    # Verify shapes\n",
    "    assert y.shape == (2, 2), f\"Output shape should be (2, 2), got {y.shape}\"\n",
    "    assert isinstance(y, Tensor), \"Output should be a Tensor\"\n",
    "    print(\"âœ… Conv2D layer forward pass successful\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Conv2D layer test failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test different kernel sizes\n",
    "try:\n",
    "    layer_3x3 = Conv2D(kernel_size=(3, 3))\n",
    "    x_5x5 = Tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [11, 12, 13, 14, 15], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]])\n",
    "    y_3x3 = layer_3x3(x_5x5)\n",
    "    \n",
    "    assert y_3x3.shape == (3, 3), f\"3x3 kernel output should be (3, 3), got {y_3x3.shape}\"\n",
    "    print(\"âœ… Different kernel sizes work correctly\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Different kernel sizes test failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Show the layer behavior\n",
    "print(\"ğŸ¯ Conv2D layer behavior:\")\n",
    "print(\"   Learnable kernel weights\")\n",
    "print(\"   Applies convolution to detect patterns\")\n",
    "print(\"   Can be trained end-to-end\")\n",
    "print(\"ğŸ“ˆ Progress: Convolution operation âœ“, Conv2D layer âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e0ff9",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Step 3: Flattening for Dense Layers\n",
    "\n",
    "### What is Flattening?\n",
    "**Flattening** converts multi-dimensional tensors to 1D vectors, enabling connection between convolutional and dense layers.\n",
    "\n",
    "### Why Flattening is Needed\n",
    "- **Interface compatibility**: Conv2D outputs 2D, Dense expects 1D\n",
    "- **Network composition**: Connect spatial features to classification\n",
    "- **Standard practice**: Almost all CNNs use this pattern\n",
    "- **Dimension management**: Preserve information while changing shape\n",
    "\n",
    "### The Pattern\n",
    "```\n",
    "Conv2D â†’ ReLU â†’ Conv2D â†’ ReLU â†’ Flatten â†’ Dense â†’ Output\n",
    "```\n",
    "\n",
    "### Real-World Usage\n",
    "- **Classification**: Final layers need 1D input for class probabilities\n",
    "- **Feature extraction**: Convert spatial features to vector representations\n",
    "- **Transfer learning**: Extract features from pre-trained CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d3729",
   "metadata": {
    "lines_to_next_cell": 1,
    "nbgrader": {
     "grade": false,
     "grade_id": "flatten-function",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def flatten(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Flatten a 2D tensor to 1D (for connecting to Dense layers).\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor to flatten\n",
    "        \n",
    "    Returns:\n",
    "        Flattened tensor with batch dimension preserved\n",
    "        \n",
    "    TODO: Implement flattening operation.\n",
    "    \n",
    "    APPROACH:\n",
    "    1. Get the numpy array from the tensor\n",
    "    2. Use .flatten() to convert to 1D\n",
    "    3. Add batch dimension with [None, :]\n",
    "    4. Return Tensor wrapped around the result\n",
    "    \n",
    "    EXAMPLE:\n",
    "    Input: Tensor([[1, 2], [3, 4]])  # shape (2, 2)\n",
    "    Output: Tensor([[1, 2, 3, 4]])  # shape (1, 4)\n",
    "    \n",
    "    HINTS:\n",
    "    - Use x.data.flatten() to get 1D array\n",
    "    - Add batch dimension: result[None, :]\n",
    "    - Return Tensor(result)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    # Flatten the tensor and add batch dimension\n",
    "    flattened = x.data.flatten()\n",
    "    result = flattened[None, :]  # Add batch dimension\n",
    "    return Tensor(result)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83cf6e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### ğŸ§ª Quick Test: Flatten Function\n",
    "\n",
    "Let's test your flatten function! This connects convolutional layers to dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdb507",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test-flatten-immediate",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test flatten function immediately after implementation\n",
    "print(\"ğŸ”¬ Testing flatten function...\")\n",
    "\n",
    "# Test case 1: 2x2 tensor\n",
    "try:\n",
    "    x = Tensor([[1, 2], [3, 4]])\n",
    "    flattened = flatten(x)\n",
    "    \n",
    "    print(f\"Input: {x}\")\n",
    "    print(f\"Flattened: {flattened}\")\n",
    "    print(f\"Flattened shape: {flattened.shape}\")\n",
    "    \n",
    "    # Verify shape and content\n",
    "    assert flattened.shape == (1, 4), f\"Flattened shape should be (1, 4), got {flattened.shape}\"\n",
    "    expected_data = np.array([[1, 2, 3, 4]])\n",
    "    assert np.array_equal(flattened.data, expected_data), f\"Flattened data should be {expected_data}, got {flattened.data}\"\n",
    "    print(\"âœ… 2x2 flatten test passed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ 2x2 flatten test failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test case 2: 3x3 tensor\n",
    "try:\n",
    "    x2 = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    flattened2 = flatten(x2)\n",
    "    \n",
    "    assert flattened2.shape == (1, 9), f\"Flattened shape should be (1, 9), got {flattened2.shape}\"\n",
    "    expected_data2 = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "    assert np.array_equal(flattened2.data, expected_data2), f\"Flattened data should be {expected_data2}, got {flattened2.data}\"\n",
    "    print(\"âœ… 3x3 flatten test passed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ 3x3 flatten test failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test case 3: Different shapes\n",
    "try:\n",
    "    x3 = Tensor([[1, 2, 3, 4], [5, 6, 7, 8]])  # 2x4\n",
    "    flattened3 = flatten(x3)\n",
    "    \n",
    "    assert flattened3.shape == (1, 8), f\"Flattened shape should be (1, 8), got {flattened3.shape}\"\n",
    "    expected_data3 = np.array([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
    "    assert np.array_equal(flattened3.data, expected_data3), f\"Flattened data should be {expected_data3}, got {flattened3.data}\"\n",
    "    print(\"âœ… Different shapes flatten test passed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Different shapes flatten test failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Show the flattening behavior\n",
    "print(\"ğŸ¯ Flatten behavior:\")\n",
    "print(\"   Converts 2D tensor to 1D\")\n",
    "print(\"   Preserves batch dimension\")\n",
    "print(\"   Enables connection to Dense layers\")\n",
    "print(\"ğŸ“ˆ Progress: Convolution operation âœ“, Conv2D layer âœ“, Flatten âœ“\")\n",
    "print(\"ğŸš€ CNN pipeline ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4717128d",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## ğŸ§ª Comprehensive CNN Testing Suite\n",
    "\n",
    "Let's test all CNN components thoroughly with realistic computer vision scenarios!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ad0ff",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "test-cnn-comprehensive",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_convolution_operations():\n",
    "    \"\"\"Test 1: Comprehensive convolution operations testing\"\"\"\n",
    "    print(\"ğŸ”¬ Testing Convolution Operations...\")\n",
    "    \n",
    "    # Test 1.1: Basic convolution\n",
    "    try:\n",
    "        input_img = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.float32)\n",
    "        identity_kernel = np.array([[1, 0], [0, 1]], dtype=np.float32)\n",
    "        \n",
    "        result = conv2d_naive(input_img, identity_kernel)\n",
    "        expected = np.array([[6, 8], [12, 14]], dtype=np.float32)\n",
    "        \n",
    "        assert np.allclose(result, expected), f\"Identity convolution failed: {result} vs {expected}\"\n",
    "        print(\"âœ… Basic convolution test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Basic convolution failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 1.2: Edge detection kernel\n",
    "    try:\n",
    "        # Vertical edge detection\n",
    "        edge_input = np.array([[0, 0, 1, 1], [0, 0, 1, 1], [0, 0, 1, 1]], dtype=np.float32)\n",
    "        vertical_edge = np.array([[-1, 1], [-1, 1]], dtype=np.float32)\n",
    "        \n",
    "        result = conv2d_naive(edge_input, vertical_edge)\n",
    "        # Should detect the vertical edge at position (0,1) and (1,1)\n",
    "        assert result[0, 1] > 0 and result[1, 1] > 0, \"Vertical edge not detected\"\n",
    "        print(\"âœ… Edge detection test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Edge detection failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 1.3: Blur kernel\n",
    "    try:\n",
    "        noise_input = np.array([[1, 0, 1], [0, 1, 0], [1, 0, 1]], dtype=np.float32)\n",
    "        blur_kernel = np.array([[0.25, 0.25], [0.25, 0.25]], dtype=np.float32)\n",
    "        \n",
    "        result = conv2d_naive(noise_input, blur_kernel)\n",
    "        # Blur should smooth out the noise\n",
    "        assert np.all(result >= 0) and np.all(result <= 1), \"Blur kernel failed\"\n",
    "        print(\"âœ… Blur kernel test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Blur kernel failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 1.4: Different kernel sizes\n",
    "    try:\n",
    "        large_input = np.random.randn(10, 10).astype(np.float32)\n",
    "        \n",
    "        # Test 3x3 kernel\n",
    "        kernel_3x3 = np.random.randn(3, 3).astype(np.float32)\n",
    "        result_3x3 = conv2d_naive(large_input, kernel_3x3)\n",
    "        assert result_3x3.shape == (8, 8), f\"3x3 kernel output shape wrong: {result_3x3.shape}\"\n",
    "        \n",
    "        # Test 5x5 kernel\n",
    "        kernel_5x5 = np.random.randn(5, 5).astype(np.float32)\n",
    "        result_5x5 = conv2d_naive(large_input, kernel_5x5)\n",
    "        assert result_5x5.shape == (6, 6), f\"5x5 kernel output shape wrong: {result_5x5.shape}\"\n",
    "        \n",
    "        print(\"âœ… Different kernel sizes test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Different kernel sizes failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"ğŸ¯ Convolution operations: All tests passed!\")\n",
    "    return True\n",
    "\n",
    "def test_conv2d_layer():\n",
    "    \"\"\"Test 2: Conv2D layer comprehensive testing\"\"\"\n",
    "    print(\"ğŸ”¬ Testing Conv2D Layer...\")\n",
    "    \n",
    "    # Test 2.1: Layer initialization\n",
    "    try:\n",
    "        layer_2x2 = Conv2D(kernel_size=(2, 2))\n",
    "        assert layer_2x2.kernel.shape == (2, 2), f\"2x2 kernel shape wrong: {layer_2x2.kernel.shape}\"\n",
    "        assert not np.allclose(layer_2x2.kernel, 0), \"Kernel should not be all zeros\"\n",
    "        \n",
    "        layer_3x3 = Conv2D(kernel_size=(3, 3))\n",
    "        assert layer_3x3.kernel.shape == (3, 3), f\"3x3 kernel shape wrong: {layer_3x3.kernel.shape}\"\n",
    "        \n",
    "        print(\"âœ… Layer initialization test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Layer initialization failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 2.2: Forward pass with different inputs\n",
    "    try:\n",
    "        layer = Conv2D(kernel_size=(2, 2))\n",
    "        \n",
    "        # Small image\n",
    "        small_img = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "        output_small = layer(small_img)\n",
    "        assert output_small.shape == (2, 2), f\"Small image output shape wrong: {output_small.shape}\"\n",
    "        assert isinstance(output_small, Tensor), \"Output should be Tensor\"\n",
    "        \n",
    "        # Larger image\n",
    "        large_img = Tensor(np.random.randn(8, 8))\n",
    "        output_large = layer(large_img)\n",
    "        assert output_large.shape == (7, 7), f\"Large image output shape wrong: {output_large.shape}\"\n",
    "        \n",
    "        print(\"âœ… Forward pass test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Forward pass failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 2.3: Learnable parameters\n",
    "    try:\n",
    "        layer1 = Conv2D(kernel_size=(2, 2))\n",
    "        layer2 = Conv2D(kernel_size=(2, 2))\n",
    "        \n",
    "        # Different layers should have different random kernels\n",
    "        assert not np.allclose(layer1.kernel, layer2.kernel), \"Different layers should have different kernels\"\n",
    "        \n",
    "        # Test that kernels are reasonable size (not too large)\n",
    "        assert np.max(np.abs(layer1.kernel)) < 1.0, \"Kernel values should be small for stable training\"\n",
    "        \n",
    "        print(\"âœ… Learnable parameters test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Learnable parameters failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 2.4: Real computer vision scenario - digit recognition\n",
    "    try:\n",
    "        # Simulate a simple 5x5 digit\n",
    "        digit_5x5 = Tensor([\n",
    "            [0, 1, 1, 1, 0],\n",
    "            [1, 0, 0, 0, 1],\n",
    "            [1, 0, 1, 0, 1],\n",
    "            [1, 0, 0, 0, 1],\n",
    "            [0, 1, 1, 1, 0]\n",
    "        ])\n",
    "        \n",
    "        # Edge detection layer\n",
    "        edge_layer = Conv2D(kernel_size=(3, 3))\n",
    "        edge_layer.kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=np.float32)\n",
    "        \n",
    "        edges = edge_layer(digit_5x5)\n",
    "        assert edges.shape == (3, 3), f\"Edge detection output shape wrong: {edges.shape}\"\n",
    "        \n",
    "        print(\"âœ… Computer vision scenario test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Computer vision scenario failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"ğŸ¯ Conv2D layer: All tests passed!\")\n",
    "    return True\n",
    "\n",
    "def test_flatten_operations():\n",
    "    \"\"\"Test 3: Flatten operations comprehensive testing\"\"\"\n",
    "    print(\"ğŸ”¬ Testing Flatten Operations...\")\n",
    "    \n",
    "    # Test 3.1: Basic flattening\n",
    "    try:\n",
    "        # 2x2 tensor\n",
    "        x_2x2 = Tensor([[1, 2], [3, 4]])\n",
    "        flat_2x2 = flatten(x_2x2)\n",
    "        \n",
    "        assert flat_2x2.shape == (1, 4), f\"2x2 flatten shape wrong: {flat_2x2.shape}\"\n",
    "        expected = np.array([[1, 2, 3, 4]])\n",
    "        assert np.array_equal(flat_2x2.data, expected), f\"2x2 flatten data wrong: {flat_2x2.data}\"\n",
    "        \n",
    "        # 3x3 tensor\n",
    "        x_3x3 = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "        flat_3x3 = flatten(x_3x3)\n",
    "        \n",
    "        assert flat_3x3.shape == (1, 9), f\"3x3 flatten shape wrong: {flat_3x3.shape}\"\n",
    "        expected = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "        assert np.array_equal(flat_3x3.data, expected), f\"3x3 flatten data wrong: {flat_3x3.data}\"\n",
    "        \n",
    "        print(\"âœ… Basic flattening test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Basic flattening failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 3.2: Different aspect ratios\n",
    "    try:\n",
    "        # Wide tensor\n",
    "        x_wide = Tensor([[1, 2, 3, 4, 5, 6]])  # 1x6\n",
    "        flat_wide = flatten(x_wide)\n",
    "        assert flat_wide.shape == (1, 6), f\"Wide flatten shape wrong: {flat_wide.shape}\"\n",
    "        \n",
    "        # Tall tensor\n",
    "        x_tall = Tensor([[1], [2], [3], [4], [5], [6]])  # 6x1\n",
    "        flat_tall = flatten(x_tall)\n",
    "        assert flat_tall.shape == (1, 6), f\"Tall flatten shape wrong: {flat_tall.shape}\"\n",
    "        \n",
    "        print(\"âœ… Different aspect ratios test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Different aspect ratios failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 3.3: Preserve data order\n",
    "    try:\n",
    "        # Test that flattening preserves row-major order\n",
    "        x_ordered = Tensor([[1, 2, 3], [4, 5, 6]])  # 2x3\n",
    "        flat_ordered = flatten(x_ordered)\n",
    "        \n",
    "        expected_order = np.array([[1, 2, 3, 4, 5, 6]])\n",
    "        assert np.array_equal(flat_ordered.data, expected_order), \"Flatten should preserve row-major order\"\n",
    "        \n",
    "        print(\"âœ… Data order preservation test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Data order preservation failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 3.4: CNN to Dense connection scenario\n",
    "    try:\n",
    "        # Simulate CNN feature map -> Dense layer\n",
    "        feature_map = Tensor([[0.1, 0.2], [0.3, 0.4]])  # 2x2 feature map\n",
    "        flattened_features = flatten(feature_map)\n",
    "        \n",
    "        # Should be ready for Dense layer input\n",
    "        assert flattened_features.shape == (1, 4), \"Feature map should flatten to (1, 4)\"\n",
    "        assert isinstance(flattened_features, Tensor), \"Should remain a Tensor\"\n",
    "        \n",
    "        # Test with Dense layer\n",
    "        dense = Dense(input_size=4, output_size=2)\n",
    "        output = dense(flattened_features)\n",
    "        assert output.shape == (1, 2), f\"Dense output shape wrong: {output.shape}\"\n",
    "        \n",
    "        print(\"âœ… CNN to Dense connection test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CNN to Dense connection failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"ğŸ¯ Flatten operations: All tests passed!\")\n",
    "    return True\n",
    "\n",
    "def test_cnn_pipelines():\n",
    "    \"\"\"Test 4: Complete CNN pipeline testing\"\"\"\n",
    "    print(\"ğŸ”¬ Testing CNN Pipelines...\")\n",
    "    \n",
    "    # Test 4.1: Simple CNN pipeline\n",
    "    try:\n",
    "        # Create pipeline: Conv2D -> ReLU -> Flatten -> Dense\n",
    "        conv = Conv2D(kernel_size=(2, 2))\n",
    "        relu = ReLU()\n",
    "        dense = Dense(input_size=4, output_size=3)\n",
    "        \n",
    "        # Input image\n",
    "        image = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "        \n",
    "        # Forward pass\n",
    "        features = conv(image)          # (3,3) -> (2,2)\n",
    "        activated = relu(features)      # (2,2) -> (2,2)\n",
    "        flattened = flatten(activated)  # (2,2) -> (1,4)\n",
    "        output = dense(flattened)       # (1,4) -> (1,3)\n",
    "        \n",
    "        assert features.shape == (2, 2), f\"Conv output shape wrong: {features.shape}\"\n",
    "        assert activated.shape == (2, 2), f\"ReLU output shape wrong: {activated.shape}\"\n",
    "        assert flattened.shape == (1, 4), f\"Flatten output shape wrong: {flattened.shape}\"\n",
    "        assert output.shape == (1, 3), f\"Dense output shape wrong: {output.shape}\"\n",
    "        \n",
    "        print(\"âœ… Simple CNN pipeline test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Simple CNN pipeline failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 4.2: Multi-layer CNN\n",
    "    try:\n",
    "        # Create deeper pipeline: Conv2D -> ReLU -> Conv2D -> ReLU -> Flatten -> Dense\n",
    "        conv1 = Conv2D(kernel_size=(2, 2))\n",
    "        relu1 = ReLU()\n",
    "        conv2 = Conv2D(kernel_size=(2, 2))\n",
    "        relu2 = ReLU()\n",
    "        dense = Dense(input_size=1, output_size=2)\n",
    "        \n",
    "        # Larger input for multi-layer processing\n",
    "        large_image = Tensor(np.random.randn(5, 5))\n",
    "        \n",
    "        # Forward pass\n",
    "        h1 = conv1(large_image)  # (5,5) -> (4,4)\n",
    "        h2 = relu1(h1)           # (4,4) -> (4,4)\n",
    "        h3 = conv2(h2)           # (4,4) -> (3,3)\n",
    "        h4 = relu2(h3)           # (3,3) -> (3,3)\n",
    "        h5 = flatten(h4)         # (3,3) -> (1,9)\n",
    "        \n",
    "        # Adjust dense layer for correct input size\n",
    "        dense_adjusted = Dense(input_size=9, output_size=2)\n",
    "        output = dense_adjusted(h5)  # (1,9) -> (1,2)\n",
    "        \n",
    "        assert h1.shape == (4, 4), f\"Conv1 output wrong: {h1.shape}\"\n",
    "        assert h3.shape == (3, 3), f\"Conv2 output wrong: {h3.shape}\"\n",
    "        assert h5.shape == (1, 9), f\"Flatten output wrong: {h5.shape}\"\n",
    "        assert output.shape == (1, 2), f\"Final output wrong: {output.shape}\"\n",
    "        \n",
    "        print(\"âœ… Multi-layer CNN test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Multi-layer CNN failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 4.3: Image classification scenario\n",
    "    try:\n",
    "        # Simulate MNIST-like 8x8 digit classification\n",
    "        digit_image = Tensor(np.random.randn(8, 8))\n",
    "        \n",
    "        # CNN for digit classification\n",
    "        feature_extractor = Conv2D(kernel_size=(3, 3))  # (8,8) -> (6,6)\n",
    "        activation = ReLU()\n",
    "        classifier_prep = flatten  # (6,6) -> (1,36)\n",
    "        classifier = Dense(input_size=36, output_size=10)  # 10 digit classes\n",
    "        \n",
    "        # Forward pass\n",
    "        features = feature_extractor(digit_image)\n",
    "        activated_features = activation(features)\n",
    "        feature_vector = classifier_prep(activated_features)\n",
    "        digit_scores = classifier(feature_vector)\n",
    "        \n",
    "        assert features.shape == (6, 6), f\"Feature extraction shape wrong: {features.shape}\"\n",
    "        assert feature_vector.shape == (1, 36), f\"Feature vector shape wrong: {feature_vector.shape}\"\n",
    "        assert digit_scores.shape == (1, 10), f\"Digit scores shape wrong: {digit_scores.shape}\"\n",
    "        \n",
    "        print(\"âœ… Image classification scenario test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Image classification scenario failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 4.4: Real-world CNN architecture pattern\n",
    "    try:\n",
    "        # Simulate LeNet-like architecture pattern\n",
    "        input_img = Tensor(np.random.randn(32, 32))  # 32x32 input image\n",
    "        \n",
    "        # First conv block\n",
    "        conv1 = Conv2D(kernel_size=(5, 5))  # (32,32) -> (28,28)\n",
    "        relu1 = ReLU()\n",
    "        \n",
    "        # Second conv block\n",
    "        conv2 = Conv2D(kernel_size=(5, 5))  # (28,28) -> (24,24)\n",
    "        relu2 = ReLU()\n",
    "        \n",
    "        # Classifier\n",
    "        classifier = Dense(input_size=24*24, output_size=3)  # 3 classes\n",
    "        \n",
    "        # Forward pass\n",
    "        h1 = relu1(conv1(input_img))\n",
    "        h2 = relu2(conv2(h1))\n",
    "        h3 = flatten(h2)\n",
    "        output = classifier(h3)\n",
    "        \n",
    "        assert h1.shape == (28, 28), f\"First conv block output wrong: {h1.shape}\"\n",
    "        assert h2.shape == (24, 24), f\"Second conv block output wrong: {h2.shape}\"\n",
    "        assert h3.shape == (1, 576), f\"Flattened features wrong: {h3.shape}\"  # 24*24 = 576\n",
    "        assert output.shape == (1, 3), f\"Classification output wrong: {output.shape}\"\n",
    "        \n",
    "        print(\"âœ… Real-world CNN architecture test passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Real-world CNN architecture failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"ğŸ¯ CNN pipelines: All tests passed!\")\n",
    "    return True\n",
    "\n",
    "# Run all comprehensive tests\n",
    "def run_comprehensive_cnn_tests():\n",
    "    \"\"\"Run all comprehensive CNN tests\"\"\"\n",
    "    print(\"ğŸ§ª Running Comprehensive CNN Test Suite...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    # Run all test functions\n",
    "    test_results.append(test_convolution_operations())\n",
    "    test_results.append(test_conv2d_layer())\n",
    "    test_results.append(test_flatten_operations())\n",
    "    test_results.append(test_cnn_pipelines())\n",
    "    \n",
    "    # Summary\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ“Š Test Results Summary:\")\n",
    "    print(f\"âœ… Convolution Operations: {'PASSED' if test_results[0] else 'FAILED'}\")\n",
    "    print(f\"âœ… Conv2D Layer: {'PASSED' if test_results[1] else 'FAILED'}\")\n",
    "    print(f\"âœ… Flatten Operations: {'PASSED' if test_results[2] else 'FAILED'}\")\n",
    "    print(f\"âœ… CNN Pipelines: {'PASSED' if test_results[3] else 'FAILED'}\")\n",
    "    \n",
    "    all_passed = all(test_results)\n",
    "    print(f\"\\nğŸ¯ Overall Result: {'ALL TESTS PASSED! ğŸ‰' if all_passed else 'SOME TESTS FAILED âŒ'}\")\n",
    "    \n",
    "    if all_passed:\n",
    "        print(\"\\nğŸš€ CNN Module Implementation Complete!\")\n",
    "        print(\"   âœ“ Convolution operations working correctly\")\n",
    "        print(\"   âœ“ Conv2D layers ready for training\")\n",
    "        print(\"   âœ“ Flatten operations connecting conv to dense layers\")\n",
    "        print(\"   âœ“ Complete CNN pipelines functional\")\n",
    "        print(\"\\nğŸ“ Ready for real computer vision applications!\")\n",
    "    \n",
    "    return all_passed\n",
    "\n",
    "# Run the comprehensive test suite\n",
    "if __name__ == \"__main__\":\n",
    "    run_comprehensive_cnn_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d92be",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### ğŸ§ª Test Your CNN Implementations\n",
    "\n",
    "Once you implement the functions above, run these cells to test them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd3f3f",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test-conv2d-naive",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test conv2d_naive function\n",
    "print(\"Testing conv2d_naive function...\")\n",
    "\n",
    "# Test case 1: Simple 3x3 input with 2x2 kernel\n",
    "input_array = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.float32)\n",
    "kernel_array = np.array([[1, 0], [0, -1]], dtype=np.float32)\n",
    "\n",
    "result = conv2d_naive(input_array, kernel_array)\n",
    "expected = np.array([[-4, -4], [-4, -4]], dtype=np.float32)\n",
    "\n",
    "print(f\"Input:\\n{input_array}\")\n",
    "print(f\"Kernel:\\n{kernel_array}\")\n",
    "print(f\"Result:\\n{result}\")\n",
    "print(f\"Expected:\\n{expected}\")\n",
    "\n",
    "assert np.allclose(result, expected), f\"conv2d_naive failed: expected {expected}, got {result}\"\n",
    "\n",
    "# Test case 2: Different kernel\n",
    "kernel2 = np.array([[1, 1], [1, 1]], dtype=np.float32)\n",
    "result2 = conv2d_naive(input_array, kernel2)\n",
    "expected2 = np.array([[12, 16], [24, 28]], dtype=np.float32)\n",
    "\n",
    "assert np.allclose(result2, expected2), f\"conv2d_naive failed: expected {expected2}, got {result2}\"\n",
    "\n",
    "print(\"âœ… conv2d_naive tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7629124",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test-conv2d-layer",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Conv2D layer\n",
    "print(\"Testing Conv2D layer...\")\n",
    "\n",
    "# Create a Conv2D layer\n",
    "layer = Conv2D(kernel_size=(2, 2))\n",
    "print(f\"Kernel size: {layer.kernel_size}\")\n",
    "print(f\"Kernel shape: {layer.kernel.shape}\")\n",
    "\n",
    "# Test with sample input\n",
    "x = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "y = layer(x)\n",
    "print(f\"Output shape: {y.shape}\")\n",
    "print(f\"Output: {y}\")\n",
    "\n",
    "# Verify shapes\n",
    "assert y.shape == (2, 2), f\"Output shape should be (2, 2), got {y.shape}\"\n",
    "assert isinstance(y, Tensor), \"Output should be a Tensor\"\n",
    "\n",
    "print(\"âœ… Conv2D layer tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3bb419",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test-flatten",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test flatten function\n",
    "print(\"Testing flatten function...\")\n",
    "\n",
    "# Test case 1: 2x2 tensor\n",
    "x = Tensor([[1, 2], [3, 4]])\n",
    "flattened = flatten(x)\n",
    "\n",
    "print(f\"Input: {x}\")\n",
    "print(f\"Flattened: {flattened}\")\n",
    "print(f\"Flattened shape: {flattened.shape}\")\n",
    "\n",
    "# Verify shape and content\n",
    "assert flattened.shape == (1, 4), f\"Flattened shape should be (1, 4), got {flattened.shape}\"\n",
    "expected_data = np.array([[1, 2, 3, 4]])\n",
    "assert np.array_equal(flattened.data, expected_data), f\"Flattened data should be {expected_data}, got {flattened.data}\"\n",
    "\n",
    "# Test case 2: 3x3 tensor\n",
    "x2 = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "flattened2 = flatten(x2)\n",
    "\n",
    "assert flattened2.shape == (1, 9), f\"Flattened shape should be (1, 9), got {flattened2.shape}\"\n",
    "expected_data2 = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "assert np.array_equal(flattened2.data, expected_data2), f\"Flattened data should be {expected_data2}, got {flattened2.data}\"\n",
    "\n",
    "print(\"âœ… Flatten tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da43a89",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test-cnn-pipeline",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test complete CNN pipeline\n",
    "print(\"Testing complete CNN pipeline...\")\n",
    "\n",
    "# Create a simple CNN pipeline: Conv2D â†’ ReLU â†’ Flatten â†’ Dense\n",
    "conv_layer = Conv2D(kernel_size=(2, 2))\n",
    "relu = ReLU()\n",
    "dense_layer = Dense(input_size=4, output_size=2)\n",
    "\n",
    "# Test input (3x3 image)\n",
    "x = Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "# Forward pass through pipeline\n",
    "h1 = conv_layer(x)\n",
    "print(f\"After Conv2D: {h1.shape}\")\n",
    "\n",
    "h2 = relu(h1)\n",
    "print(f\"After ReLU: {h2.shape}\")\n",
    "\n",
    "h3 = flatten(h2)\n",
    "print(f\"After Flatten: {h3.shape}\")\n",
    "\n",
    "h4 = dense_layer(h3)\n",
    "print(f\"After Dense: {h4.shape}\")\n",
    "\n",
    "# Verify pipeline works\n",
    "assert h1.shape == (2, 2), f\"Conv2D output should be (2, 2), got {h1.shape}\"\n",
    "assert h2.shape == (2, 2), f\"ReLU output should be (2, 2), got {h2.shape}\"\n",
    "assert h3.shape == (1, 4), f\"Flatten output should be (1, 4), got {h3.shape}\"\n",
    "assert h4.shape == (1, 2), f\"Dense output should be (1, 2), got {h4.shape}\"\n",
    "\n",
    "print(\"âœ… CNN pipeline tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30be278",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## ğŸ¯ Module Summary\n",
    "\n",
    "Congratulations! You've successfully implemented the core components of convolutional neural networks:\n",
    "\n",
    "### What You've Accomplished\n",
    "âœ… **Convolution Operation**: Implemented conv2d_naive with sliding window from scratch  \n",
    "âœ… **Conv2D Layer**: Built a learnable convolutional layer with random kernel initialization  \n",
    "âœ… **Flattening**: Created the bridge between convolutional and dense layers  \n",
    "âœ… **CNN Pipeline**: Composed Conv2D â†’ ReLU â†’ Flatten â†’ Dense for complete networks  \n",
    "âœ… **Spatial Pattern Detection**: Understanding how convolution detects local features  \n",
    "\n",
    "### Key Concepts You've Learned\n",
    "- **Convolution is pattern matching**: Kernels detect specific spatial patterns\n",
    "- **Parameter sharing**: Same kernel applied everywhere for translation invariance\n",
    "- **Local connectivity**: Each output depends only on a small input region\n",
    "- **Spatial hierarchy**: Multiple layers build increasingly complex features\n",
    "- **Dimension management**: Flattening connects spatial and vector representations\n",
    "\n",
    "### Mathematical Foundations\n",
    "- **Convolution operation**: (I * K)[i,j] = Î£Î£ I[i+m, j+n] Ã— K[m,n]\n",
    "- **Sliding window**: Kernel moves across input computing dot products\n",
    "- **Feature maps**: Convolution outputs that highlight detected patterns\n",
    "- **Translation invariance**: Same pattern detected regardless of position\n",
    "\n",
    "### Real-World Applications\n",
    "- **Computer vision**: Object recognition, face detection, medical imaging\n",
    "- **Image processing**: Edge detection, noise reduction, enhancement\n",
    "- **Autonomous systems**: Traffic sign recognition, obstacle detection\n",
    "- **Scientific imaging**: Satellite imagery, microscopy, astronomy\n",
    "\n",
    "### Next Steps\n",
    "1. **Export your code**: `tito package nbdev --export 05_cnn`\n",
    "2. **Test your implementation**: `tito module test 05_cnn`\n",
    "3. **Use your CNN components**: \n",
    "   ```python\n",
    "   from tinytorch.core.cnn import Conv2D, conv2d_naive, flatten\n",
    "   from tinytorch.core.layers import Dense\n",
    "   from tinytorch.core.activations import ReLU\n",
    "   \n",
    "   # Create CNN pipeline\n",
    "   conv = Conv2D((3, 3))\n",
    "   relu = ReLU()\n",
    "   dense = Dense(16, 10)\n",
    "   \n",
    "   # Process image\n",
    "   features = conv(image)\n",
    "   activated = relu(features)\n",
    "   flattened = flatten(activated)\n",
    "   output = dense(flattened)\n",
    "   ```\n",
    "4. **Move to Module 6**: Start building data loading and preprocessing pipelines!\n",
    "\n",
    "**Ready for the next challenge?** Let's build efficient data loading systems to feed our networks!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
