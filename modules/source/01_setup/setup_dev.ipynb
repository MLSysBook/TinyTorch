{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23615e70",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Setup - TinyTorch System Configuration\n",
    "\n",
    "Welcome to TinyTorch! This module configures your development environment and establishes professional ML engineering practices.\n",
    "\n",
    "## Learning Goals\n",
    "- Configure personal developer identification for your TinyTorch installation\n",
    "- Query system information for hardware-aware ML development\n",
    "- Master the NBGrader workflow: implement â†’ test â†’ export\n",
    "- Build functions that integrate into your tinytorch package\n",
    "\n",
    "## Why Configuration Matters in ML Systems\n",
    "Every production ML system needs proper configuration:\n",
    "- **Developer attribution**: Professional identification and contact info\n",
    "- **System awareness**: Understanding hardware limitations and capabilities\n",
    "- **Reproducibility**: Documenting exact environment for experiment tracking\n",
    "- **Debugging support**: System specs help troubleshoot performance issues\n",
    "\n",
    "You'll learn to build ML systems that understand their environment and identify their creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdc6fe",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup-imports",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp core.setup\n",
    "\n",
    "#| export\n",
    "import sys\n",
    "import platform\n",
    "import psutil\n",
    "import os\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cbf79",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup-verification",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"ðŸ”¥ TinyTorch Setup Module\")\n",
    "print(f\"Python version: {sys.version_info.major}.{sys.version_info.minor}\")\n",
    "print(f\"Platform: {platform.system()}\")\n",
    "print(\"Ready to configure your TinyTorch installation!\\n\")\n",
    "\n",
    "# Display configuration workflow\n",
    "print(\"Configuration Workflow:\")\n",
    "print(\"Personal Information â†’ System Information â†’ Complete\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a82b2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Personal Information Configuration\n",
    "\n",
    "### The 5 C's Framework\n",
    "Before we implement, let's understand what we're building through our 5 C's approach:\n",
    "\n",
    "#### Concept\n",
    "\n",
    "What is Personal Information Configuration?\n",
    "Personal information identifies you as the creator of ML systems. Every professional system needs proper attribution - just like Git commits have author info, your TinyTorch installation needs your identity.\n",
    "\n",
    "#### Code Structure\n",
    "\n",
    "What We're Building:\n",
    "```python\n",
    "def personal_info() -> Dict[str, str]:     # Returns developer identity\n",
    "    return {                               # Dictionary with required fields\n",
    "        'developer': 'Your Name',         # Your actual name\n",
    "        'email': 'your@domain.com',       # Contact information\n",
    "        'institution': 'Your Place',      # Affiliation\n",
    "        'system_name': 'YourName-Dev',    # Unique system identifier\n",
    "        'version': '1.0.0'                # Configuration version\n",
    "    }\n",
    "```\n",
    "\n",
    "#### Connections\n",
    "\n",
    "Real-World Equivalents:\n",
    "- **Git commits**: Author name and email in every commit\n",
    "- **Docker images**: Maintainer information in container metadata\n",
    "- **Python packages**: Author info in setup.py and pyproject.toml\n",
    "- **ML model cards**: Creator information for model attribution\n",
    "\n",
    "#### Constraints\n",
    "\n",
    "Key Implementation Requirements:\n",
    "- Use your actual information (not placeholder text)\n",
    "- Email must contain @ and domain\n",
    "- System name should be unique and descriptive\n",
    "- All values must be strings, keep version as '1.0.0'\n",
    "\n",
    "#### Context\n",
    "\n",
    "**You're establishing your professional identity in the ML systems world.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3350854",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "personal-info",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def personal_info() -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Return personal information for this TinyTorch installation.\n",
    "    \n",
    "    This function configures your personal TinyTorch installation with your identity.\n",
    "    It's the foundation of proper ML engineering practices - every system needs\n",
    "    to know who built it and how to contact them.\n",
    "    \n",
    "    TODO: Implement personal information configuration.\n",
    "    \n",
    "    STEP-BY-STEP IMPLEMENTATION:\n",
    "    1. Create a dictionary with your personal details\n",
    "    2. Include all required keys: developer, email, institution, system_name, version\n",
    "    3. Use your actual information (not placeholder text)\n",
    "    4. Make system_name unique and descriptive\n",
    "    5. Keep version as '1.0.0' for now\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, str]: Personal configuration with developer identity\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    return {\n",
    "        'developer': 'Student Name',\n",
    "        'email': 'student@university.edu',\n",
    "        'institution': 'University Name',\n",
    "        'system_name': 'StudentName-TinyTorch-Dev',\n",
    "        'version': '1.0.0'\n",
    "    }\n",
    "    ### END SOLUTION\n",
    "\n",
    "# Test and validate the personal_info function\n",
    "def test_personal_info_comprehensive():\n",
    "    \"\"\"Comprehensive test for personal_info function.\"\"\"\n",
    "    print(\"ðŸ”¬ Testing Personal Information Configuration...\")\n",
    "    \n",
    "    # Test personal_info function\n",
    "    personal = personal_info()\n",
    "    \n",
    "    # Test return type\n",
    "    assert isinstance(personal, dict), \"personal_info should return a dictionary\"\n",
    "    \n",
    "    # Test required keys\n",
    "    required_keys = ['developer', 'email', 'institution', 'system_name', 'version']\n",
    "    for key in required_keys:\n",
    "        assert key in personal, f\"Dictionary should have '{key}' key\"\n",
    "    \n",
    "    # Test non-empty values\n",
    "    for key, value in personal.items():\n",
    "        assert isinstance(value, str), f\"Value for '{key}' should be a string\"\n",
    "        assert len(value) > 0, f\"Value for '{key}' cannot be empty\"\n",
    "    \n",
    "    # Test email format\n",
    "    assert '@' in personal['email'], \"Email should contain @ symbol\"\n",
    "    assert '.' in personal['email'], \"Email should contain domain\"\n",
    "    \n",
    "    # Test version format\n",
    "    assert personal['version'] == '1.0.0', \"Version should be '1.0.0'\"\n",
    "    \n",
    "    # Test system name (should be unique/personalized)\n",
    "    assert len(personal['system_name']) > 5, \"System name should be descriptive\"\n",
    "    \n",
    "    print(\"âœ… All personal info tests passed!\")\n",
    "    print(f\"âœ… TinyTorch configured for: {personal['developer']}\")\n",
    "    print(f\"âœ… Contact: {personal['email']}\")\n",
    "    print(f\"âœ… System: {personal['system_name']}\")\n",
    "    return personal\n",
    "\n",
    "# Run comprehensive test and display results\n",
    "personal_config = test_personal_info_comprehensive()\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… Personal Information Configuration COMPLETE\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a18f2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## System Information Collection\n",
    "\n",
    "### The 5 C's Framework\n",
    "Before we implement, let's understand what we're building through our 5 C's approach:\n",
    "\n",
    "#### Concept\n",
    "\n",
    "What is System Information Collection?\n",
    "System information detection provides hardware and software specs that ML systems need for performance optimization. Think computer specifications for gaming - ML needs to know what resources are available.\n",
    "\n",
    "#### Code Structure\n",
    "\n",
    "What We're Building:\n",
    "```python\n",
    "def system_info() -> Dict[str, Any]:       # Queries system specs\n",
    "    return {                               # Hardware/software details\n",
    "        'python_version': '3.9.7',        # Python compatibility\n",
    "        'platform': 'Darwin',             # Operating system\n",
    "        'architecture': 'arm64',          # CPU architecture\n",
    "        'cpu_count': 8,                   # Parallel processing cores\n",
    "        'memory_gb': 16.0                 # Available RAM in GB\n",
    "    }\n",
    "```\n",
    "\n",
    "#### Connections\n",
    "\n",
    "Real-World Equivalents:\n",
    "- **PyTorch**: `torch.get_num_threads()` uses CPU count for optimization\n",
    "- **TensorFlow**: `tf.config.list_physical_devices()` queries hardware\n",
    "- **Scikit-learn**: `n_jobs=-1` uses all available CPU cores\n",
    "- **MLflow**: Documents system environment for experiment reproducibility\n",
    "\n",
    "#### Constraints\n",
    "\n",
    "Key Implementation Requirements:\n",
    "- Use actual system queries (not hardcoded values)\n",
    "- Convert memory from bytes to GB for readability\n",
    "- Round memory to 1 decimal place for clean output\n",
    "- Return proper data types (strings, int, float)\n",
    "\n",
    "#### Context\n",
    "\n",
    "**You're building ML systems that adapt intelligently to their hardware environment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ab563",
   "metadata": {
    "lines_to_next_cell": 1,
    "nbgrader": {
     "grade": false,
     "grade_id": "system-info",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def system_info() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Query and return system information for this TinyTorch installation.\n",
    "    \n",
    "    This function gathers crucial hardware and software information that affects\n",
    "    ML performance, compatibility, and debugging. It's the foundation of \n",
    "    hardware-aware ML systems.\n",
    "    \n",
    "    TODO: Implement system information queries.\n",
    "    \n",
    "    STEP-BY-STEP IMPLEMENTATION:\n",
    "    1. Get Python version using sys.version_info\n",
    "    2. Get platform using platform.system()\n",
    "    3. Get architecture using platform.machine()\n",
    "    4. Get CPU count using psutil.cpu_count()\n",
    "    5. Get memory using psutil.virtual_memory().total\n",
    "    6. Convert memory from bytes to GB (divide by 1024^3)\n",
    "    7. Return all information in a dictionary\n",
    "    \n",
    "    EXAMPLE OUTPUT:\n",
    "    {\n",
    "        'python_version': '3.9.7',\n",
    "        'platform': 'Darwin', \n",
    "        'architecture': 'arm64',\n",
    "        'cpu_count': 8,\n",
    "        'memory_gb': 16.0\n",
    "    }\n",
    "    \n",
    "    IMPLEMENTATION HINTS:\n",
    "    - Use f-string formatting for Python version: f\"{major}.{minor}.{micro}\"\n",
    "    - Memory conversion: bytes / (1024^3) = GB\n",
    "    - Round memory to 1 decimal place for readability\n",
    "    - Make sure data types are correct (strings for text, int for cpu_count, float for memory_gb)\n",
    "    \n",
    "    LEARNING CONNECTIONS:\n",
    "    - This is like `torch.cuda.is_available()` in PyTorch\n",
    "    - Similar to system info in MLflow experiment tracking\n",
    "    - Parallels hardware detection in TensorFlow\n",
    "    - Foundation for performance optimization in ML systems\n",
    "    \n",
    "    PERFORMANCE IMPLICATIONS:\n",
    "    - cpu_count affects parallel processing capabilities\n",
    "    - memory_gb determines maximum model and batch sizes\n",
    "    - platform affects file system and process management\n",
    "    - architecture influences numerical precision and optimization\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    # Get Python version\n",
    "    version_info = sys.version_info\n",
    "    python_version = f\"{version_info.major}.{version_info.minor}.{version_info.micro}\"\n",
    "    \n",
    "    # Get platform information\n",
    "    platform_name = platform.system()\n",
    "    architecture = platform.machine()\n",
    "    \n",
    "    # Get CPU information\n",
    "    cpu_count = psutil.cpu_count()\n",
    "    \n",
    "    # Get memory information (convert bytes to GB)\n",
    "    memory_bytes = psutil.virtual_memory().total\n",
    "    memory_gb = round(memory_bytes / (1024**3), 1)\n",
    "    \n",
    "    return {\n",
    "        'python_version': python_version,\n",
    "        'platform': platform_name,\n",
    "        'architecture': architecture,\n",
    "        'cpu_count': cpu_count,\n",
    "        'memory_gb': memory_gb\n",
    "    }\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584d0e9",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "### ðŸ§ª Unit Test: System Information Query\n",
    "\n",
    "This test validates your `system_info()` function implementation, ensuring it accurately detects and reports hardware and software specifications for performance optimization and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94825aa",
   "metadata": {
    "lines_to_next_cell": 2,
    "nbgrader": {
     "grade": true,
     "grade_id": "test-system-info-immediate",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_unit_system_info_basic():\n",
    "    \"\"\"Test system_info function implementation.\"\"\"\n",
    "    print(\"ðŸ”¬ Unit Test: System Information...\")\n",
    "    \n",
    "    # Test system_info function\n",
    "    sys_info = system_info()\n",
    "    \n",
    "    # Test return type\n",
    "    assert isinstance(sys_info, dict), \"system_info should return a dictionary\"\n",
    "    \n",
    "    # Test required keys\n",
    "    required_keys = ['python_version', 'platform', 'architecture', 'cpu_count', 'memory_gb']\n",
    "    for key in required_keys:\n",
    "        assert key in sys_info, f\"Dictionary should have '{key}' key\"\n",
    "    \n",
    "    # Test data types\n",
    "    assert isinstance(sys_info['python_version'], str), \"python_version should be string\"\n",
    "    assert isinstance(sys_info['platform'], str), \"platform should be string\"\n",
    "    assert isinstance(sys_info['architecture'], str), \"architecture should be string\"\n",
    "    assert isinstance(sys_info['cpu_count'], int), \"cpu_count should be integer\"\n",
    "    assert isinstance(sys_info['memory_gb'], (int, float)), \"memory_gb should be number\"\n",
    "    \n",
    "    # Test reasonable values\n",
    "    assert sys_info['cpu_count'] > 0, \"CPU count should be positive\"\n",
    "    assert sys_info['memory_gb'] > 0, \"Memory should be positive\"\n",
    "    assert len(sys_info['python_version']) > 0, \"Python version should not be empty\"\n",
    "    \n",
    "    # Test that values are actually queried (not hardcoded)\n",
    "    actual_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "    assert sys_info['python_version'] == actual_version, \"Python version should match actual system\"\n",
    "    \n",
    "    print(\"âœ… System info function tests passed!\")\n",
    "    print(f\"âœ… Python: {sys_info['python_version']} on {sys_info['platform']}\")\n",
    "\n",
    "# Run the test\n",
    "test_unit_system_info_basic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097da88",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Module Summary: TinyTorch Setup Complete\n",
    "\n",
    "Congratulations! You've successfully configured your TinyTorch development environment and established professional ML engineering practices.\n",
    "\n",
    "### What You've Accomplished\n",
    "âœ… **Personal Configuration**: Established developer identity and system attribution  \n",
    "âœ… **System Information**: Built hardware-aware ML system foundation  \n",
    "âœ… **Testing Integration**: Implemented comprehensive validation for both functions  \n",
    "âœ… **Professional Workflow**: Mastered NBGrader solution blocks and testing  \n",
    "\n",
    "Your TinyTorch installation is now properly configured with:\n",
    "- **Developer attribution** for professional collaboration\n",
    "- **Hardware detection** for performance optimization\n",
    "- **Tested functions** ready for package integration\n",
    "\n",
    "### Key ML Systems Concepts Learned\n",
    "- **Configuration management**: Professional setup and attribution standards\n",
    "- **Hardware awareness**: System specs affect ML performance and capabilities\n",
    "- **Testing practices**: Comprehensive validation ensures reliability\n",
    "- **Package development**: Functions become part of production codebase\n",
    "\n",
    "### Next Steps\n",
    "1. **Export your work**: Use `tito module export 01_setup` to integrate with TinyTorch\n",
    "2. **Verify integration**: Test that your functions work in the tinytorch package\n",
    "3. **Ready for tensors**: Move on to building the fundamental ML data structure\n",
    "\n",
    "**You've built the foundation - now let's construct the ML system on top of it!**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
