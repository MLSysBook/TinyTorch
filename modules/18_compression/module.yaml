name: Compression
number: 17
type: optimization
difficulty: advanced
estimated_hours: 8-10

description: |
  Model compression through pruning and sparsity. Students learn to identify and remove
  redundant parameters, achieving 70-80% sparsity while maintaining accuracy. Essential
  for edge deployment and mobile devices.

learning_objectives:
  - Understand sparsity and redundancy in neural networks
  - Implement magnitude-based pruning
  - Build structured and unstructured pruning
  - Measure accuracy vs model size tradeoffs

prerequisites:
  - Module 15: Acceleration
  - Module 16: Quantization

skills_developed:
  - Pruning techniques
  - Sparsity management
  - Model compression
  - Edge deployment optimization

exports:
  - tinytorch.optimizations.compression