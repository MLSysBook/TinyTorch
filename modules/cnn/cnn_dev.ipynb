{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "jupyter:\n",
        "  jupytext:\n",
        "    text_representation:\n",
        "      extension: .py\n",
        "      format_name: percent\n",
        "      format_version: '1.3'\n",
        "      jupytext_version: 1.17.1\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Module X: CNN - Convolutional Neural Networks\n",
        "\n",
        "Welcome to the CNN module! Here you'll implement the core building block of modern computer vision: the convolutional layer.\n",
        "\n",
        "## Learning Goals\n",
        "- Understand the convolution operation (sliding window, local connectivity, weight sharing)\n",
        "- Implement Conv2D with explicit for-loops\n",
        "- Visualize how convolution builds feature maps\n",
        "- Compose Conv2D with other layers to build a simple ConvNet\n",
        "- (Stretch) Explore stride, padding, pooling, and multi-channel input\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| default_exp core.cnn\n",
        "\n",
        "# Setup and imports\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tinytorch.core.tensor import Tensor\n",
        "from tinytorch.core.layers import Dense\n",
        "from tinytorch.core.activations import ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "## Step 1: What is Convolution?\n",
        "\n",
        "A convolutional layer applies a small filter (kernel) across the input, producing a feature map. This operation captures local patterns and is the foundation of modern vision models.\n",
        "\n",
        "- **Local connectivity:** Each output value depends only on a small region of the input.\n",
        "- **Weight sharing:** The same filter is applied everywhere.\n",
        "- **Sliding window:** The filter moves across the input spatially.\n",
        "\n",
        "We'll start with a single-channel (grayscale) 2D convolution, no stride or padding.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| export\n",
        "def conv2d_naive(input: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Naive 2D convolution (single channel, no stride, no padding).\n",
        "    Args:\n",
        "        input: 2D input array (H, W)\n",
        "        kernel: 2D filter (kH, kW)\n",
        "    Returns:\n",
        "        2D output array (H-kH+1, W-kW+1)\n",
        "    TODO: Implement the sliding window convolution using for-loops.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"Student implementation required\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| hide\n",
        "#| export\n",
        "def conv2d_naive(input: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
        "    H, W = input.shape\n",
        "    kH, kW = kernel.shape\n",
        "    out_H, out_W = H - kH + 1, W - kW + 1\n",
        "    output = np.zeros((out_H, out_W), dtype=input.dtype)\n",
        "    for i in range(out_H):\n",
        "        for j in range(out_W):\n",
        "            output[i, j] = np.sum(input[i:i+kH, j:j+kW] * kernel)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "### üß™ Test Your Conv2D Implementation\n",
        "\n",
        "Try your function on this simple example:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test case for conv2d_naive\n",
        "input = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "], dtype=np.float32)\n",
        "kernel = np.array([\n",
        "    [1, 0],\n",
        "    [0, -1]\n",
        "], dtype=np.float32)\n",
        "\n",
        "expected = np.array([\n",
        "    [1*1+2*0+4*0+5*(-1), 2*1+3*0+5*0+6*(-1)],\n",
        "    [4*1+5*0+7*0+8*(-1), 5*1+6*0+8*0+9*(-1)]\n",
        "], dtype=np.float32)\n",
        "\n",
        "try:\n",
        "    output = conv2d_naive(input, kernel)\n",
        "    print(\"Output:\\n\", output)\n",
        "    print(\"Expected:\\n\", expected)\n",
        "    assert np.allclose(output, expected), \"‚ùå Output does not match expected!\"\n",
        "    print(\"‚úÖ conv2d_naive works!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"Make sure to implement conv2d_naive above!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "## Step 2: Conv2D Layer Class\n",
        "\n",
        "Now let's wrap your function in a layer class for use in networks.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| export\n",
        "class Conv2D:\n",
        "    \"\"\"\n",
        "    2D Convolutional Layer (single channel, single filter, no stride/pad).\n",
        "    Args:\n",
        "        kernel_size: (kH, kW)\n",
        "    TODO: Initialize a random kernel and implement the forward pass using conv2d_naive.\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size: Tuple[int, int]):\n",
        "        raise NotImplementedError(\"Student implementation required\")\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        raise NotImplementedError(\"Student implementation required\")\n",
        "    def __call__(self, x: Tensor) -> Tensor:\n",
        "        return self.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| hide\n",
        "#| export\n",
        "class Conv2D:\n",
        "    def __init__(self, kernel_size: Tuple[int, int]):\n",
        "        self.kernel = np.random.randn(*kernel_size).astype(np.float32)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return Tensor(conv2d_naive(x.data, self.kernel))\n",
        "    def __call__(self, x: Tensor) -> Tensor:\n",
        "        return self.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "## Step 3: Provided Utilities (Stretch Goals)\n",
        "- Stride and padding utilities (provided or as stretch)\n",
        "- Multi-channel and multi-filter support (provided or as stretch)\n",
        "- Pooling (optional)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| export\n",
        "def flatten(x: Tensor) -> Tensor:\n",
        "    \"\"\"Flatten a 2D tensor to 1D (for connecting to Dense).\"\"\"\n",
        "    return Tensor(x.data.flatten()[None, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "## Step 4: Compose a Simple ConvNet\n",
        "\n",
        "Now you can build a simple ConvNet:\n",
        "- Conv2D ‚Üí ReLU ‚Üí Flatten ‚Üí Dense\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compose a simple ConvNet\n",
        "try:\n",
        "    conv = Conv2D((2, 2))\n",
        "    relu = ReLU()\n",
        "    dense = Dense(4, 1)\n",
        "    x = Tensor(np.random.randn(3, 3).astype(np.float32))\n",
        "    out = dense(flatten(relu(conv(x))))\n",
        "    print(\"ConvNet output:\", out.data)\n",
        "    print(\"‚úÖ Simple ConvNet works!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"Check your Conv2D and flatten implementations!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "## Step 5: Visualization (Provided)\n",
        "\n",
        "Visualize the sliding window and feature map construction.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Provided visualization for convolution\n",
        "import matplotlib.patches as patches\n",
        "def visualize_conv2d(input, kernel, output):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    axes[0].imshow(input, cmap='Blues')\n",
        "    axes[0].set_title('Input')\n",
        "    axes[1].imshow(kernel, cmap='Reds')\n",
        "    axes[1].set_title('Kernel')\n",
        "    axes[2].imshow(output, cmap='Greens')\n",
        "    axes[2].set_title('Output Feature Map')\n",
        "    plt.show()\n",
        "\n",
        "# Example visualization\n",
        "try:\n",
        "    output = conv2d_naive(input, kernel)\n",
        "    visualize_conv2d(input, kernel, output)\n",
        "except Exception as e:\n",
        "    print(\"Visualization skipped (conv2d_naive not implemented yet)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "## Step 6: Tests (Provided)\n",
        "\n",
        "Test your Conv2D layer on more examples and edge cases.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# More tests for Conv2D\n",
        "try:\n",
        "    x = Tensor(np.ones((5, 5), dtype=np.float32))\n",
        "    conv = Conv2D((3, 3))\n",
        "    out = conv(x)\n",
        "    print(\"Conv2D output shape:\", out.shape)\n",
        "    assert out.shape == (3, 3), \"‚ùå Output shape incorrect!\"\n",
        "    print(\"‚úÖ Conv2D layer passes shape test!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"Check your Conv2D implementation!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
