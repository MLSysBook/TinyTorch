name: "Competition & Validation"
module_number: "20"
description: "TorchPerf Olympics preparation - validation, baseline, and competition submission"
difficulty: "⭐⭐⭐" # 3 stars - capstone integration
estimated_time: "1-2 hours"

prerequisites:
  - "Module 19: Benchmarking"
  - "Modules 14-18: Optimization techniques"

learning_objectives:
  - "Validate TinyTorch installation and environment"
  - "Generate baseline performance metrics"
  - "Understand complete optimization workflow"
  - "Create standardized competition submissions"

key_concepts:
  - "System validation and environment checks"
  - "Baseline generation and reference metrics"
  - "End-to-end optimization workflow"
  - "Competition submission format"

skills_developed:
  - "Systematic validation and testing"
  - "Performance measurement and comparison"
  - "Integration of multiple optimization techniques"
  - "Professional submission preparation"

exports_to: "tinytorch/competition/submit.py"

test_coverage:
  - "Installation validation"
  - "Baseline generation"
  - "Worked example workflow"
  - "Competition template structure"

connections:
  builds_on:
    - "Module 19 for benchmarking tools"
    - "Modules 14-18 for optimization techniques"
  enables:
    - "TorchPerf Olympics competition participation"
    - "Systematic performance optimization"
    - "Professional ML systems workflow"

notes: |
  This is the capstone module that brings together all previous modules.
  It's lightweight (no new techniques) but shows the complete workflow from
  validation through optimization to submission.
  
  Students learn:
  1. How to validate their environment works
  2. What baseline performance looks like
  3. How to apply optimizations systematically
  4. How to package work for competition
  
  The module includes a complete worked example and a template for students
  to implement their own optimization strategies.

