description: 'Model compression through pruning and sparsity. Students learn to identify
  and remove

  redundant parameters, achieving 70-80% sparsity while maintaining accuracy. Essential

  for edge deployment and mobile devices.

  '
difficulty: advanced
estimated_hours: 8-10
exports:
- tinytorch.optimizations.compression
learning_objectives:
- Understand sparsity and redundancy in neural networks
- Implement magnitude-based pruning
- Build structured and unstructured pruning
- Measure accuracy vs model size tradeoffs
name: Compression
number: 17
prerequisites:
- Module 15: Acceleration
- Module 16: Quantization
skills_developed:
- Pruning techniques
- Sparsity management
- Model compression
- Edge deployment optimization
type: optimization
