#!/usr/bin/env python3
"""
ğŸš€ CAPABILITY SHOWCASE: Image Processing 
After Module 06 (Spatial)

"Look what you built!" - Your convolutions can see patterns!
"""

import sys
import time
import numpy as np
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.layout import Layout
from rich.align import Align

# Import from YOUR TinyTorch implementation
try:
    from tinytorch.core.tensor import Tensor
    from tinytorch.core.spatial import Conv2D, MaxPool2D
except ImportError:
    print("âŒ TinyTorch spatial layers not found. Make sure you've completed Module 06 (Spatial)!")
    sys.exit(1)

console = Console()

def create_sample_image():
    """Create a sample image with clear features for edge detection."""
    # 8x8 image with a square in the middle
    image = np.zeros((8, 8))
    image[2:6, 2:6] = 1.0  # White square in center
    return image

def create_noisy_image():
    """Create an image with noise to show filtering effects."""
    # Create a diagonal line with noise
    image = np.random.random((8, 8)) * 0.3  # Background noise
    for i in range(8):
        if i < 8:
            image[i, i] = 1.0  # Diagonal line
    return image

def ascii_image(image, chars=" â–‘â–’â–“â–ˆ"):
    """Convert image to ASCII art."""
    lines = []
    for row in image:
        line = ""
        for pixel in row:
            # Normalize pixel value to char index
            char_idx = int(pixel * (len(chars) - 1))
            char_idx = max(0, min(char_idx, len(chars) - 1))
            line += chars[char_idx]
        lines.append(line)
    return "\n".join(lines)

def display_image_comparison(original, filtered, title, filter_name):
    """Display original and filtered images side by side."""
    console.print(Panel.fit(f"[bold cyan]{title}[/bold cyan]", border_style="cyan"))
    
    # Create side-by-side display
    table = Table(show_header=True, show_edge=False)
    table.add_column("Original Image", style="white")
    table.add_column("After " + filter_name, style="yellow")
    
    orig_lines = ascii_image(original).split('\n')
    filt_lines = ascii_image(filtered).split('\n')
    
    for orig_line, filt_line in zip(orig_lines, filt_lines):
        table.add_row(orig_line, filt_line)
    
    console.print(table)

def demonstrate_edge_detection():
    """Show edge detection with convolution."""
    console.print(Panel.fit("ğŸ” EDGE DETECTION WITH YOUR CONVOLUTIONS", style="bold green"))
    
    # Create edge detection kernel (vertical edges)
    edge_kernel = np.array([
        [[-1, 0, 1],
         [-2, 0, 2], 
         [-1, 0, 1]]
    ])
    
    console.print("ğŸ§® Edge Detection Kernel (Sobel):")
    console.print("   [-1  0  1]")
    console.print("   [-2  0  2]")
    console.print("   [-1  0  1]")
    console.print()
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("Creating convolution layer...", total=None)
        time.sleep(1)
        
        # Create convolution layer with YOUR implementation
        conv = Conv2D(in_channels=1, out_channels=1, kernel_size=3, padding=1)
        
        # Set the edge detection kernel
        conv.weights = Tensor([[edge_kernel]])  # Shape: (1, 1, 3, 3)
        conv.bias = Tensor([0])
        
        progress.update(task, description="âœ… Edge detector ready!")
        time.sleep(0.5)
    
    # Test on sample image
    sample_image = create_sample_image()
    console.print("\nğŸ“¸ Testing on sample image...")
    
    # Reshape for convolution (add batch and channel dimensions)
    input_tensor = Tensor([[sample_image.tolist()]])  # Shape: (1, 1, 8, 8)
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("Applying convolution...", total=None)
        time.sleep(1)
        
        # Apply YOUR convolution
        output = conv.forward(input_tensor)
        filtered_image = np.array(output.data[0][0])  # Extract image from tensor
        
        progress.update(task, description="âœ… Edge detection complete!")
        time.sleep(0.5)
    
    # Normalize for display
    filtered_image = np.abs(filtered_image)  # Take absolute value
    if filtered_image.max() > 0:
        filtered_image = filtered_image / filtered_image.max()
    
    display_image_comparison(sample_image, filtered_image, 
                           "Edge Detection Results", "Sobel Filter")
    
    console.print("\nğŸ’¡ [bold]What happened:[/bold]")
    console.print("   ğŸ¯ Vertical edges were detected and highlighted")
    console.print("   ğŸ¯ The convolution found brightness changes")
    console.print("   ğŸ¯ This is how CNNs 'see' features in images!")

def demonstrate_blur_filter():
    """Show blur/smoothing with convolution."""
    console.print(Panel.fit("ğŸŒ«ï¸ NOISE REDUCTION WITH BLUR FILTER", style="bold blue"))
    
    # Create blur kernel (Gaussian-like)
    blur_kernel = np.array([
        [[1, 2, 1],
         [2, 4, 2],
         [1, 2, 1]]
    ]) / 16.0  # Normalize
    
    console.print("ğŸ§® Blur Kernel (Gaussian-like):")
    console.print("   [1  2  1]    / 16")
    console.print("   [2  4  2]   ")
    console.print("   [1  2  1]   ")
    console.print()
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("Creating blur filter...", total=None)
        time.sleep(1)
        
        # Create convolution layer for blurring
        blur_conv = Conv2D(in_channels=1, out_channels=1, kernel_size=3, padding=1)
        blur_conv.weights = Tensor([[blur_kernel]])
        blur_conv.bias = Tensor([0])
        
        progress.update(task, description="âœ… Blur filter ready!")
        time.sleep(0.5)
    
    # Test on noisy image
    noisy_image = create_noisy_image()
    console.print("\nğŸ“¸ Testing on noisy image...")
    
    input_tensor = Tensor([[noisy_image.tolist()]])
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("Applying blur filter...", total=None)
        time.sleep(1)
        
        output = blur_conv.forward(input_tensor)
        blurred_image = np.array(output.data[0][0])
        
        progress.update(task, description="âœ… Image smoothed!")
        time.sleep(0.5)
    
    display_image_comparison(noisy_image, blurred_image,
                           "Noise Reduction Results", "Blur Filter")
    
    console.print("\nğŸ’¡ [bold]What happened:[/bold]")
    console.print("   ğŸ¯ Random noise was smoothed out")
    console.print("   ğŸ¯ The diagonal line is preserved")
    console.print("   ğŸ¯ This is preprocessing for better feature detection!")

def demonstrate_pooling():
    """Show max pooling for downsampling."""
    console.print(Panel.fit("ğŸ“‰ DOWNSAMPLING WITH MAX POOLING", style="bold yellow"))
    
    console.print("ğŸ”§ Max Pooling Operation:")
    console.print("   Takes maximum value in each 2Ã—2 region")
    console.print("   Reduces spatial dimensions by half")
    console.print("   Keeps strongest features")
    console.print()
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("Creating max pooling layer...", total=None)
        time.sleep(1)
        
        # Create max pooling layer
        maxpool = MaxPool2D(kernel_size=2, stride=2)
        
        progress.update(task, description="âœ… Max pooling ready!")
        time.sleep(0.5)
    
    # Create test image with clear patterns
    test_image = np.array([
        [1, 1, 0, 0, 1, 1, 0, 0],
        [1, 1, 0, 0, 1, 1, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 1],
        [0, 0, 1, 1, 0, 0, 1, 1],
        [1, 1, 0, 0, 1, 1, 0, 0],
        [1, 1, 0, 0, 1, 1, 0, 0],
        [0, 0, 1, 1, 0, 0, 1, 1],
        [0, 0, 1, 1, 0, 0, 1, 1]
    ])
    
    input_tensor = Tensor([[test_image.tolist()]])
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("Applying max pooling...", total=None)
        time.sleep(1)
        
        pooled_output = maxpool.forward(input_tensor)
        pooled_image = np.array(pooled_output.data[0][0])
        
        progress.update(task, description="âœ… Downsampling complete!")
        time.sleep(0.5)
    
    display_image_comparison(test_image, pooled_image,
                           f"Max Pooling Results (8Ã—8 â†’ {pooled_image.shape[0]}Ã—{pooled_image.shape[1]})",
                           "Max Pool 2Ã—2")
    
    console.print("\nğŸ’¡ [bold]What happened:[/bold]")
    console.print("   ğŸ¯ Image size reduced from 8Ã—8 to 4Ã—4")
    console.print("   ğŸ¯ Important features were preserved")
    console.print("   ğŸ¯ This makes CNNs more efficient and translation-invariant!")

def show_cnn_architecture_preview():
    """Preview how these operations combine in CNNs."""
    console.print(Panel.fit("ğŸ—ï¸ CNN ARCHITECTURE PREVIEW", style="bold magenta"))
    
    console.print("ğŸ§  Your spatial operations are the building blocks of CNNs:")
    console.print()
    console.print("   ğŸ“¥ Input Image")
    console.print("   â†“")
    console.print("   ğŸ” Conv2D + ReLU  â† [bold cyan]Feature Detection[/bold cyan]")
    console.print("   â†“")  
    console.print("   ğŸ“‰ MaxPool2D      â† [bold yellow]Spatial Reduction[/bold yellow]")
    console.print("   â†“")
    console.print("   ğŸ” Conv2D + ReLU  â† [bold cyan]Higher-level Features[/bold cyan]")
    console.print("   â†“")
    console.print("   ğŸ“‰ MaxPool2D      â† [bold yellow]Further Reduction[/bold yellow]")
    console.print("   â†“")
    console.print("   ğŸ§® Dense Layers   â† [bold green]Classification[/bold green]")
    console.print("   â†“")
    console.print("   ğŸ“¤ Predictions")
    console.print()
    console.print("ğŸ¯ [bold]Real CNN Examples:[/bold]")
    console.print("   â€¢ LeNet-5: Handwritten digit recognition")
    console.print("   â€¢ AlexNet: ImageNet classification breakthrough") 
    console.print("   â€¢ ResNet: Deep networks with skip connections")
    console.print("   â€¢ U-Net: Medical image segmentation")

def show_production_applications():
    """Show real-world applications of convolutions."""
    console.print(Panel.fit("ğŸŒ PRODUCTION APPLICATIONS", style="bold red"))
    
    console.print("ğŸš€ Your convolution operations power:")
    console.print()
    console.print("   ğŸ“± [bold]Computer Vision:[/bold]")
    console.print("      â€¢ Photo apps (Instagram filters)")
    console.print("      â€¢ Medical imaging (X-ray analysis)")
    console.print("      â€¢ Autonomous vehicles (object detection)")
    console.print("      â€¢ Security systems (face recognition)")
    console.print()
    console.print("   ğŸ­ [bold]Industrial Applications:[/bold]")
    console.print("      â€¢ Quality control in manufacturing")
    console.print("      â€¢ Satellite image analysis")
    console.print("      â€¢ Document processing (OCR)")
    console.print("      â€¢ Agricultural monitoring")
    console.print()
    console.print("   âš¡ [bold]Performance Optimizations:[/bold]")
    console.print("      â€¢ GPU acceleration (thousands of parallel ops)")
    console.print("      â€¢ Winograd convolution algorithms")
    console.print("      â€¢ Quantization for mobile deployment")
    console.print("      â€¢ TensorRT optimization for inference")

def main():
    """Main showcase function."""
    console.clear()
    
    # Header
    header = Panel.fit(
        "[bold cyan]ğŸš€ CAPABILITY SHOWCASE: IMAGE PROCESSING[/bold cyan]\n"
        "[yellow]After Module 06 (Spatial)[/yellow]\n\n"
        "[green]\"Look what you built!\" - Your convolutions can see patterns![/green]",
        border_style="bright_blue"
    )
    console.print(Align.center(header))
    console.print()
    
    try:
        demonstrate_edge_detection()
        console.print("\n" + "="*60)
        
        demonstrate_blur_filter()
        console.print("\n" + "="*60)
        
        demonstrate_pooling()
        console.print("\n" + "="*60)
        
        show_cnn_architecture_preview()
        console.print("\n" + "="*60)
        
        show_production_applications()
        
        # Celebration
        console.print("\n" + "="*60)
        console.print(Panel.fit(
            "[bold green]ğŸ‰ COMPUTER VISION MASTERY! ğŸ‰[/bold green]\n\n"
            "[cyan]Your Conv2D and MaxPool2D layers are the foundation[/cyan]\n"
            "[cyan]of EVERY modern computer vision system![/cyan]\n\n"
            "[white]These same operations power:[/white]\n"
            "[white]â€¢ Self-driving cars[/white]\n"
            "[white]â€¢ Medical diagnosis AI[/white]\n"
            "[white]â€¢ Photo recognition apps[/white]\n"
            "[white]â€¢ Industrial quality control[/white]\n\n"
            "[yellow]Next up: Attention (Module 07) - The transformer revolution![/yellow]",
            border_style="green"
        ))
        
    except Exception as e:
        console.print(f"âŒ Error running showcase: {e}")
        console.print("ğŸ’¡ Make sure you've completed Module 06 and your spatial layers work!")
        import traceback
        console.print(f"Debug info: {traceback.format_exc()}")

if __name__ == "__main__":
    main()