# AUTOGENERATED! DO NOT EDIT! File to edit: ../../modules/cnn/cnn_dev.ipynb.

# %% auto 0
__all__ = ['conv2d_naive', 'Conv2D', 'flatten']

# %% ../../modules/cnn/cnn_dev.ipynb 4
def conv2d_naive(input: np.ndarray, kernel: np.ndarray) -> np.ndarray:
    """
    Naive 2D convolution (single channel, no stride, no padding).
    Args:
        input: 2D input array (H, W)
        kernel: 2D filter (kH, kW)
    Returns:
        2D output array (H-kH+1, W-kW+1)
    TODO: Implement the sliding window convolution using for-loops.
    """
    raise NotImplementedError("Student implementation required")

# %% ../../modules/cnn/cnn_dev.ipynb 5
def conv2d_naive(input: np.ndarray, kernel: np.ndarray) -> np.ndarray:
    H, W = input.shape
    kH, kW = kernel.shape
    out_H, out_W = H - kH + 1, W - kW + 1
    output = np.zeros((out_H, out_W), dtype=input.dtype)
    for i in range(out_H):
        for j in range(out_W):
            output[i, j] = np.sum(input[i:i+kH, j:j+kW] * kernel)
    return output

# %% ../../modules/cnn/cnn_dev.ipynb 9
class Conv2D:
    """
    2D Convolutional Layer (single channel, single filter, no stride/pad).
    Args:
        kernel_size: (kH, kW)
    TODO: Initialize a random kernel and implement the forward pass using conv2d_naive.
    """
    def __init__(self, kernel_size: Tuple[int, int]):
        raise NotImplementedError("Student implementation required")
    def forward(self, x: Tensor) -> Tensor:
        raise NotImplementedError("Student implementation required")
    def __call__(self, x: Tensor) -> Tensor:
        return self.forward(x)

# %% ../../modules/cnn/cnn_dev.ipynb 10
class Conv2D:
    def __init__(self, kernel_size: Tuple[int, int]):
        self.kernel = np.random.randn(*kernel_size).astype(np.float32)
    def forward(self, x: Tensor) -> Tensor:
        return Tensor(conv2d_naive(x.data, self.kernel))
    def __call__(self, x: Tensor) -> Tensor:
        return self.forward(x)

# %% ../../modules/cnn/cnn_dev.ipynb 12
def flatten(x: Tensor) -> Tensor:
    """Flatten a 2D tensor to 1D (for connecting to Dense)."""
    return Tensor(x.data.flatten()[None, :])
